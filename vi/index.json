[
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.5-event5/",
	"title": "Event 5",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AWS Well-Architected Security Pillar” Mục Đích Của Sự Kiện Hiểu rõ về vai trò của Security Pillar trong AWS Well-Architected Framework: Tìm hiểu các best practices về bảo mật và cách áp dụng chúng trong kiến trúc đám mây, tập trung vào các dịch vụ và công cụ của AWS.\nKhám phá các nguyên tắc bảo mật cốt lõi: Tìm hiểu về các nguyên tắc Least Privilege, Zero Trust, và Defense in Depth trong việc triển khai bảo mật cho hệ thống đám mây.\nNhận diện các mối đe dọa bảo mật trong môi trường đám mây tại Việt Nam: Thảo luận về những thách thức bảo mật và các mối đe dọa phổ biến đối với các tổ chức đang vận hành trên nền tảng đám mây tại Việt Nam.\nKhám phá các pillar bảo mật trong AWS: Tìm hiểu chi tiết về 5 pillar bảo mật trong AWS gồm Identity \u0026amp; Access Management, Detection, Infrastructure Protection, Data Protection, và Incident Response, và cách thực hiện chúng một cách hiệu quả.\nNội Dung Nổi Bật Opening \u0026amp; Security Foundation Security Pillar trong Well-Architected Framework: Giới thiệu về tầm quan trọng của Security Pillar trong AWS Well-Architected Framework và cách bảo vệ hệ thống trong kiến trúc đám mây.\nCác nguyên tắc cốt lõi: Nhấn mạnh các nguyên tắc Least Privilege, Zero Trust, và Defense in Depth là cơ sở để thiết kế các hệ thống bảo mật vững mạnh.\nShared Responsibility Model: Hiểu rõ mô hình chia sẻ trách nhiệm giữa AWS và khách hàng trong việc bảo mật đám mây.\nCác mối đe dọa bảo mật phổ biến tại Việt Nam: Phân tích các mối đe dọa bảo mật mà các tổ chức ở Việt Nam gặp phải khi vận hành trên nền tảng đám mây.\nPillar 1 — Identity \u0026amp; Access Management Kiến trúc IAM hiện đại: Cách sử dụng Identity and Access Management (IAM) trong AWS, bao gồm người dùng, vai trò, chính sách và tầm quan trọng của việc tránh sử dụng thông tin đăng nhập dài hạn.\nIAM Identity Center: Giới thiệu Single Sign-On (SSO) và permission sets để quản lý quyền truy cập xuyên suốt các tài khoản AWS.\nSCP và Permission Boundaries: Sử dụng Service Control Policies (SCP) và permission boundaries để quản lý bảo mật trong môi trường đa tài khoản.\nMFA, quay vòng thông tin xác thực, Access Analyzer: Cách sử dụng Multi-Factor Authentication (MFA), quay vòng thông tin xác thực và Access Analyzer để đảm bảo quyền truy cập an toàn.\nMini Demo: Xác thực chính sách IAM và mô phỏng quyền truy cập để hiểu cách IAM hoạt động thực tế.\nPillar 2 — Detection Phát hiện và giám sát liên tục: Giới thiệu các công cụ CloudTrail, GuardDuty, và Security Hub để theo dõi và phát hiện các sự kiện bảo mật trong môi trường AWS.\nLogging ở mọi lớp: Thực hành việc ghi log ở các lớp khác nhau như VPC Flow Logs, ALB/S3 logs để giám sát bảo mật đầy đủ.\nCảnh báo \u0026amp; Tự động hóa với EventBridge: Cách sử dụng EventBridge để thiết lập cảnh báo và tự động phản hồi sự cố bảo mật.\nDetection-as-Code: Áp dụng Detection-as-Code cho hạ tầng và các quy tắc bảo mật để tự động hóa quá trình phát hiện sự cố.\nPillar 3 — Infrastructure Protection Bảo mật mạng và Workload: Tìm hiểu về VPC segmentation và cách phân chia giữa private và public placement để bảo vệ lưu lượng mạng.\nSecurity Groups vs NACLs: So sánh sự khác biệt giữa Security Groups và Network Access Control Lists (NACLs) và áp dụng mô hình nào cho từng trường hợp cụ thể.\nWAF + Shield + Network Firewall: Bảo vệ ứng dụng và mạng bằng các công cụ AWS WAF (Web Application Firewall), Shield, và Network Firewall để giảm thiểu các mối đe dọa.\nBảo vệ Workload: Các best practices bảo mật cho EC2, ECS và EKS để bảo vệ các workload trong đám mây.\nPillar 4 — Data Protection Mã hóa, khóa và bí mật: Giới thiệu AWS KMS (Key Management Service) và các chính sách, cấp phép và quay vòng khóa để bảo vệ dữ liệu.\nMã hóa dữ liệu khi nghỉ và khi truyền: Cách thực hiện mã hóa cho dữ liệu khi nghỉ (e.g., S3, EBS, RDS) và khi truyền (e.g., DynamoDB).\nQuản lý Bí mật: Quản lý các dữ liệu nhạy cảm như mật khẩu, khóa, và mã thông qua Secrets Manager và Parameter Store, và thực hiện quay vòng bí mật.\nPhân loại dữ liệu và các biện pháp bảo vệ quyền truy cập: Áp dụng các biện pháp phân loại dữ liệu và kiểm soát quyền truy cập để bảo vệ dữ liệu.\nPillar 5 — Incident Response Playbook \u0026amp; Tự động hóa IR: Cách triển khai vòng đời Incident Response (IR) theo AWS và tự động hóa quy trình phản ứng sự cố bằng AWS.\nPlaybook IR: Các tình huống sự cố phổ biến như IAM key bị xâm phạm, S3 bị công khai và EC2 bị nhiễm mã độc, và cách giải quyết chúng.\nPhản ứng tự động bằng Lambda/Step Functions: Sử dụng AWS Lambda và Step Functions để tự động hóa các hành động phản ứng sự cố và giảm thiểu thiệt hại nhanh chóng.\nTổng kết \u0026amp; Q\u0026amp;A Tổng kết 5 pillar: Tóm tắt lại 5 pillar bảo mật và cách áp dụng chúng vào môi trường AWS thực tế.\nCác sai sót phổ biến và thực tế doanh nghiệp Việt Nam: Thảo luận về những thách thức bảo mật mà các doanh nghiệp Việt Nam gặp phải và cách giải quyết chúng bằng các công cụ AWS.\nLộ trình học bảo mật: Giới thiệu các chứng chỉ Security Specialty và Solutions Architect – Professional (SA Pro) và lộ trình học cho những người muốn chuyên sâu về bảo mật.\nNhững Gì Học Được Nguyên Tắc và Pillars Bảo Mật Nguyên tắc bảo mật cốt lõi: Hiểu rõ về Least Privilege, Zero Trust, và Defense in Depth trong thiết kế bảo mật hệ thống.\nCác Pillars bảo mật của AWS: Tầm quan trọng của các pillar bảo mật: Identity \u0026amp; Access Management, Detection, Infrastructure Protection, Data Protection, và Incident Response trong việc bảo vệ môi trường AWS.\nIAM và Quản lý Quyền Truy Cập Kiến trúc IAM hiện đại: Cách sử dụng IAM để quản lý quyền truy cập một cách an toàn và hiệu quả, đồng thời tránh sử dụng thông tin đăng nhập dài hạn.\nBảo mật đa tài khoản: Áp dụng SCP và permission boundaries để quản lý bảo mật cho nhiều tài khoản AWS.\nGiám sát và Phát hiện Liên Tục CloudTrail, GuardDuty, và Security Hub: Cài đặt và sử dụng các công cụ như CloudTrail và GuardDuty để theo dõi hoạt động và phát hiện các sự kiện bảo mật.\nLogging và Tự động hóa: Thực hành các best practices trong việc ghi log và tự động cảnh báo sự cố bảo mật bằng EventBridge.\nBảo vệ Dữ liệu KMS và Mã hóa: Áp dụng AWS KMS và các phương pháp mã hóa dữ liệu để bảo vệ dữ liệu nhạy cảm.\nQuản lý Bí mật: Sử dụng Secrets Manager và Parameter Store để quản lý bí mật và thực hiện quay vòng tự động.\nPhản ứng Sự Cố Tự động hóa Phản ứng Sự Cố: Cách sử dụng AWS Lambda và Step Functions để tự động hóa các phản ứng sự cố, giảm thiểu thời gian và thiệt hại. Ứng Dụng Vào Công Việc Quản lý IAM: Áp dụng IAM policies và role-based access control trong tổ chức để đảm bảo quyền truy cập an toàn.\nGiám sát liên tục: Thiết lập CloudTrail, GuardDuty, và Security Hub để giám sát các mối đe dọa bảo mật trong môi trường AWS.\nTự động hóa phản ứng sự cố: Sử dụng Lambda và Step Functions để tự động hóa các hành động phản ứng sự cố, tăng hiệu quả bảo mật.\nMã hóa dữ liệu: Thực hiện mã hóa cho data-at-rest và data-in-transit, bảo vệ dữ liệu trong quá trình sử dụng và truyền tải.\nTrải Nghiệm Trong Sự Kiện Học hỏi từ các chuyên gia AWS: Sự kiện cung cấp những kiến thức sâu sắc về bảo mật đám mây và cách áp dụng các công cụ bảo mật của AWS.\nDemos thực hành: Các bài demo thực tế về IAM, IR automation, và Security Monitoring giúp tôi hiểu rõ hơn về cách áp dụng bảo mật trong công việc của mình.\nMạng lưới và chia sẻ kinh nghiệm: Sự kiện tạo cơ hội để kết nối và chia sẻ kiến thức với các chuyên gia và đồng nghiệp trong ngành bảo mật.\nKết luận Sự kiện “AWS Well-Architected Security Pillar” đã cung cấp cho tôi những kiến thức quan trọng về các nguyên tắc bảo mật và cách áp dụng AWS tools để bảo vệ hệ thống đám mây. Các pillar bảo mật như IAM, Phát hiện liên tục, Bảo vệ dữ liệu, và Phản ứng sự cố sẽ là những yếu tố quan trọng trong việc triển khai và duy trì bảo mật hệ thống AWS của tôi.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “DevOps on AWS” Mục Đích Của Sự Kiện Cung cấp cái nhìn tổng quan về các khái niệm và ứng dụng AI/ML trong môi trường DevOps.\nGiới thiệu và làm rõ văn hóa DevOps, các nguyên tắc cốt lõi giúp tăng hiệu quả làm việc nhóm và tự động hóa.\nHiểu rõ các chỉ số đo lường hiệu quả DevOps như DORA metrics, MTTR, và tần suất triển khai để đánh giá và cải thiện quy trình.\nHỗ trợ các bạn intern nắm bắt kiến thức thiết yếu, áp dụng hiệu quả vào dự án thực tế nhằm hoàn thành công việc đúng tiến độ và đạt chất lượng.\nNội Dung Nổi Bật 1. Recap AI/ML Session Tóm tắt các khái niệm AI/ML cơ bản và ứng dụng thực tế trong phát triển phần mềm và DevOps.\nCác công cụ và dịch vụ AI/ML hỗ trợ tự động hóa và phân tích dữ liệu trong quy trình DevOps.\n2. DevOps Culture and Principles Giới thiệu văn hóa DevOps: hợp tác liên phòng ban, tự động hóa, cải tiến liên tục.\nCác nguyên tắc cốt lõi trong DevOps giúp tăng tốc độ phát triển và độ tin cậy của phần mềm.\n3. Benefits and Key Metrics Tầm quan trọng của việc đo lường hiệu suất DevOps thông qua các chỉ số:\nDORA metrics: Lead Time, Deployment Frequency, Change Failure Rate, Mean Time to Recovery (MTTR).\nÝ nghĩa và cách cải thiện các chỉ số để tối ưu quy trình phát triển và vận hành.\n4. Ứng dụng thực tế cho Intern Hướng dẫn cách áp dụng kiến thức DevOps và AI/ML vào dự án.\nCác tips và best practices giúp intern hoàn thành project hiệu quả.\nTăng cường kỹ năng làm việc nhóm và giao tiếp trong môi trường DevOps.\nPillar 1 — AWS DevOps Services - CI/CD Pipeline Trình bày kiến trúc IAM hiện đại bao gồm các yếu tố: người dùng, vai trò, chính sách, và nhấn mạnh việc tránh dùng thông tin đăng nhập dài hạn để giảm thiểu rủi ro.\nGiới thiệu IAM Identity Center với tính năng Single Sign-On (SSO) và permission sets giúp quản lý quyền truy cập thống nhất trên nhiều tài khoản AWS.\nGiải thích vai trò của Service Control Policies (SCP) và permission boundaries trong việc kiểm soát quyền hạn trong môi trường đa tài khoản, giúp tăng cường bảo mật.\nTrình bày cách sử dụng Multi-Factor Authentication (MFA), quay vòng thông tin xác thực (credential rotation) và Access Analyzer để bảo vệ quyền truy cập an toàn và chính xác.\nDemo minh họa xác thực chính sách IAM và mô phỏng quyền truy cập để người tham dự hiểu rõ cách IAM vận hành thực tế trong môi trường AWS.\nPillar 2 — Infrastructure as Code (IaC) Giới thiệu các công cụ theo dõi và giám sát bảo mật như CloudTrail (ghi lại lịch sử API), GuardDuty (phát hiện mối đe dọa), và Security Hub (tổng hợp cảnh báo bảo mật).\nThực hành ghi log chi tiết ở nhiều lớp khác nhau như VPC Flow Logs (lưu lượng mạng), ALB/S3 logs để đảm bảo giám sát toàn diện và phát hiện sớm các sự cố.\nHướng dẫn sử dụng EventBridge để thiết lập cảnh báo tự động và kích hoạt các hành động phản ứng khi phát hiện sự cố bảo mật.\nÁp dụng Detection-as-Code: xây dựng các quy tắc phát hiện sự cố tự động dựa trên mã để tăng tính tự động hóa và hiệu quả trong quản lý bảo mật.\nPillar 3 — Container Services on AWS Tìm hiểu cách bảo vệ mạng và workload trên AWS bằng phân đoạn VPC, phân chia lưu lượng giữa private và public để giảm thiểu rủi ro từ mạng công cộng.\nSo sánh và áp dụng Security Groups và Network ACLs (NACLs) cho từng tình huống bảo mật, nhằm kiểm soát lưu lượng mạng ra/vào phù hợp.\nGiới thiệu các dịch vụ bảo vệ lớp ứng dụng và mạng như AWS WAF (Web Application Firewall), Shield (chống DDoS) và Network Firewall để bảo vệ toàn diện.\nTrình bày các best practices bảo mật cho workloads trên EC2, ECS, và EKS, giúp duy trì an toàn cho các ứng dụng container và máy chủ ảo.\nPillar 4 — Monitoring \u0026amp; Observability Giới thiệu AWS Key Management Service (KMS) cho việc quản lý khóa mã hóa, cùng với chính sách, cấp phép và quay vòng khóa nhằm bảo vệ dữ liệu.\nTrình bày các kỹ thuật mã hóa dữ liệu khi nghỉ (at-rest) như trên S3, EBS, RDS, và khi truyền (in-transit) như trong DynamoDB và các dịch vụ AWS khác.\nHướng dẫn quản lý dữ liệu nhạy cảm thông qua Secrets Manager và Parameter Store, bao gồm quy trình quay vòng tự động để giảm thiểu rủi ro.\nThảo luận về phân loại dữ liệu và các biện pháp kiểm soát truy cập để đảm bảo dữ liệu chỉ được truy cập bởi người dùng và hệ thống có thẩm quyền.\nPillar 5 — DevOps Best Practices \u0026amp; Case Studies Giới thiệu cách triển khai Incident Response (IR) theo quy trình chuẩn AWS, kết hợp tự động hóa để nhanh chóng xử lý các sự cố bảo mật.\nTrình bày các playbook IR cho những tình huống phổ biến như lộ IAM key, bucket S3 bị công khai, hoặc EC2 bị nhiễm mã độc, cùng hướng xử lý chi tiết.\nMinh họa sử dụng AWS Lambda và Step Functions để tự động hóa phản ứng sự cố, giảm thiểu thời gian phát hiện và khắc phục sự cố nhanh hơn.\nTổng kết \u0026amp; Q\u0026amp;A Tóm tắt 5 pillar bảo mật chính trong AWS và cách áp dụng thực tế giúp doanh nghiệp xây dựng hệ thống đám mây an toàn, hiệu quả.\nThảo luận về những lỗi phổ biến và thách thức bảo mật trong các doanh nghiệp Việt Nam, đồng thời đề xuất các giải pháp dựa trên công cụ AWS.\nGiới thiệu lộ trình học tập và các chứng chỉ chuyên sâu về bảo mật như AWS Security Specialty và Solutions Architect – Professional (SA Pro) dành cho người muốn nâng cao kỹ năng.\nNhững Gì Học Được Văn hóa và Nguyên tắc DevOps Hiểu rõ văn hóa DevOps, các nguyên tắc giúp tăng cường hợp tác liên phòng ban, tự động hóa và cải tiến liên tục trong phát triển phần mềm. Nắm được tầm quan trọng của việc đo lường hiệu quả DevOps qua các chỉ số chính như DORA metrics (Lead Time, Deployment Frequency, Change Failure Rate) và MTTR để nâng cao chất lượng dự án. AI/ML trong DevOps Nhận diện các ứng dụng AI/ML giúp tự động hóa và phân tích dữ liệu trong quy trình DevOps. Ứng dụng AI/ML hỗ trợ tối ưu hóa pipeline và phát hiện sự cố nhanh chóng. AWS DevOps Services và Bảo Mật Tìm hiểu kiến trúc IAM hiện đại và cách quản lý quyền truy cập an toàn bằng IAM Identity Center, SCP, permission boundaries. Sử dụng MFA, credential rotation và Access Analyzer để tăng cường bảo mật cho tài khoản và dịch vụ. Thực hành demo về xác thực policy và mô phỏng quyền truy cập trong AWS IAM. Giám sát và Phát hiện liên tục Ứng dụng các công cụ AWS như CloudTrail, GuardDuty, Security Hub để giám sát toàn diện và phát hiện sự cố bảo mật. Thiết lập logging ở nhiều lớp và sử dụng EventBridge để tự động cảnh báo, phản ứng nhanh với các sự cố bảo mật. Quản lý mạng và Container Phân đoạn mạng (VPC), áp dụng Security Groups và NACLs để bảo vệ workloads trên EC2, ECS, EKS. Sử dụng AWS WAF, Shield và Network Firewall nhằm phòng thủ nhiều lớp trước các cuộc tấn công mạng. Bảo vệ dữ liệu và Mã hóa Sử dụng AWS KMS để quản lý khóa mã hóa, bảo vệ dữ liệu at-rest và in-transit. Quản lý bí mật và thực hiện quay vòng tự động thông qua Secrets Manager và Parameter Store. Áp dụng phân loại dữ liệu và kiểm soát truy cập chặt chẽ. Phản ứng sự cố tự động Xây dựng playbook Incident Response với các bước detection → analysis → containment → recovery. Tự động hóa xử lý sự cố bảo mật bằng AWS Lambda và Step Functions để giảm thiểu thiệt hại. Học cách xử lý các tình huống phổ biến như IAM key leak, S3 bucket public ngoài ý muốn, hoặc EC2 bị nhiễm malware. Ứng Dụng Vào Công Việc Áp dụng kiến thức IAM và quản lý quyền truy cập cho các dự án thực tế. Thiết lập hệ thống giám sát và cảnh báo tự động để tăng cường an toàn cho môi trường AWS. Tích hợp tự động hóa phản ứng sự cố giúp tiết kiệm thời gian và giảm rủi ro. Mã hóa dữ liệu và quản lý bí mật chặt chẽ nhằm đảm bảo tuân thủ chính sách bảo mật. Trải Nghiệm Trong Sự Kiện Được học hỏi trực tiếp từ các chuyên gia AWS và trải nghiệm các demo thực hành về bảo mật, DevOps. Có cơ hội trao đổi, kết nối với cộng đồng DevOps và bảo mật, mở rộng kiến thức chuyên môn. Nhận được những lời khuyên thực tiễn và hướng dẫn áp dụng phù hợp cho công việc và dự án cá nhân. Kết Luận Sự kiện “DevOps on AWS” giúp tôi có cái nhìn toàn diện về văn hóa DevOps, ứng dụng AI/ML và các best practices bảo mật trên nền tảng AWS. Những kiến thức về IAM, giám sát, bảo vệ dữ liệu và phản ứng sự cố sẽ là nền tảng quan trọng để tôi áp dụng trong các dự án, đặc biệt hỗ trợ tốt cho các bạn intern hoàn thành công việc hiệu quả và an toàn hơn.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AI/ML/GenAI on AWS” Mục Đích Của Sự Kiện Khám phá các dịch vụ AI/ML của AWS: Cung cấp cái nhìn tổng quan về các dịch vụ AI/ML hiện có của AWS, giúp người tham gia hiểu rõ cách ứng dụng các dịch vụ này trong các dự án thực tế.\nGiới thiệu về Generative AI: Tập trung vào việc ứng dụng các mô hình nền tảng và Generative AI trong môi trường AWS để xây dựng các ứng dụng thông minh.\nTrình diễn thực tế về Generative AI: Hướng dẫn cách xây dựng chatbot sử dụng Amazon Bedrock và các kỹ thuật như prompt engineering, chain-of-thought reasoning.\nCung cấp kiến thức về MLOps và SageMaker: Giới thiệu các công cụ quản lý vòng đời mô hình máy học từ việc chuẩn bị dữ liệu, huấn luyện mô hình đến triển khai và giám sát.\nNội Dung Nổi Bật Giới thiệu về AI/ML tại AWS: Amazon SageMaker: Nền tảng máy học toàn diện giúp triển khai, huấn luyện và quản lý mô hình máy học.\nData preparation and labeling: Các công cụ hỗ trợ chuẩn bị và gán nhãn dữ liệu.\nMLOps capabilities: Các tính năng tích hợp trong SageMaker để hỗ trợ quy trình vận hành mô hình (MLOps).\nLive Demo – SageMaker Studio walkthrough: Trình diễn sử dụng SageMaker Studio để phát triển và triển khai mô hình AI/ML. Generative AI with Amazon Bedrock: Foundation Models: Giới thiệu các mô hình nền tảng như Claude, Llama, Titan, và hướng dẫn lựa chọn mô hình phù hợp.\nPrompt Engineering: Các kỹ thuật xây dựng câu lệnh để tối ưu hóa hiệu quả của các mô hình Generative AI, bao gồm Chain-of-Thought reasoning và Few-shot learning.\nRetrieval-Augmented Generation (RAG): Kiến trúc và cách tích hợp Knowledge Base vào quá trình tạo nội dung từ mô hình.\nBedrock Agents: Xây dựng các quy trình làm việc đa bước và tích hợp các công cụ trong Amazon Bedrock.\nGuardrails: Các biện pháp đảm bảo tính an toàn và lọc nội dung khi sử dụng Generative AI.\nLive Demo – Generative AI Chatbot with Bedrock: Trình diễn xây dựng một chatbot sử dụng Amazon Bedrock. Những Gì Học Được Tư duy thiết kế với AI/ML: Amazon SageMaker là nền tảng chủ lực hỗ trợ toàn bộ vòng đời mô hình, từ việc chuẩn bị dữ liệu đến triển khai và giám sát mô hình.\nPrompt Engineering: Làm thế nào để tối ưu hóa các mô hình Generative AI bằng các kỹ thuật xây dựng câu lệnh hiệu quả.\nMLOps: Cách quản lý và tự động hóa quá trình huấn luyện, triển khai và giám sát các mô hình AI trong môi trường sản xuất.\nGenerative AI: Tìm hiểu về các mô hình nền tảng và cách chúng có thể tạo ra nội dung sáng tạo và chatbot thông minh.\nKiến trúc AI/ML: Foundation Models: Sự khác biệt giữa các mô hình như Claude, Llama, và Titan, và cách lựa chọn mô hình phù hợp với yêu cầu cụ thể của dự án.\nRAG (Retrieval-Augmented Generation): Hiểu về cách kiến trúc RAG hoạt động và cách tích hợp kiến thức từ cơ sở dữ liệu vào quy trình tạo ra nội dung.\nBedrock Agents: Hướng dẫn xây dựng các quy trình làm việc phức tạp với các công cụ tích hợp sẵn.\nỨng Dụng Vào Công Việc Áp dụng Amazon SageMaker: Tích hợp các công cụ của SageMaker để chuẩn bị dữ liệu, huấn luyện và triển khai mô hình AI trong các dự án hiện tại.\nXây dựng Generative AI Chatbot: Sử dụng Amazon Bedrock để phát triển chatbot và các ứng dụng sử dụng mô hình Generative AI cho các dự án dịch vụ khách hàng hoặc trợ lý ảo.\nTối ưu hóa mô hình AI/ML với Prompt Engineering: Áp dụng kỹ thuật prompt engineering trong việc tối ưu hóa mô hình AI để tạo ra kết quả chính xác và hiệu quả hơn.\nMLOps: Triển khai MLOps trong môi trường công ty để tự động hóa quy trình huấn luyện và giám sát mô hình AI, giúp tăng hiệu quả và giảm thiểu rủi ro.\nTrải nghiệm trong event Học hỏi từ các chuyên gia AWS: Các diễn giả chia sẻ kiến thức chuyên sâu về AI/ML và Generative AI, giúp tôi hiểu rõ hơn về cách sử dụng các công cụ của AWS để phát triển mô hình.\nTrình diễn trực tiếp: Tham gia vào các buổi demo thực tế về SageMaker và Amazon Bedrock, qua đó giúp tôi hình dung cách xây dựng và triển khai các mô hình AI trong môi trường thực tế.\nKết nối và trao đổi: Sự kiện giúp tôi kết nối với những người tham gia khác và các chuyên gia, mở rộng mối quan hệ và trao đổi kinh nghiệm về AI/ML.\nKết luận Sự kiện “AI/ML/GenAI on AWS” đã cung cấp cho tôi những kiến thức quan trọng về các công nghệ mới trong AI/ML, đặc biệt là về Generative AI và các công cụ AWS hỗ trợ như SageMaker và Amazon Bedrock. Các kỹ thuật Prompt Engineering và MLOps cũng đã giúp tôi nhận ra các bước cần thiết để đưa các mô hình AI từ ý tưởng đến sản phẩm thực tế.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “AI-Driven Development Life Cycle: Reimagining Software Engineering” Mục Đích Của Sự Kiện Khám phá AI-Driven Development Life Cycle và cách AI thay đổi quy trình phát triển phần mềm hiện đại.\nTìm hiểu cách Amazon Q Developer và Kiro hỗ trợ lập trình viên trong việc phân tích yêu cầu, sinh mã nguồn, kiểm thử và tối ưu hóa hiệu suất phát triển.\nNhận diện những ứng dụng thực tế của AI trong phát triển phần mềm tại Việt Nam: tăng năng suất, giảm lỗi, cải thiện tốc độ triển khai sản phẩm.\nKhám phá các giai đoạn của vòng đời phát triển phần mềm dựa trên AI: Requirement → Design → Coding → Testing → Deployment → Improvement.\nNội Dung Nổi Bật Opening \u0026amp; Software Engineering Foundation Tổng quan về sự chuyển dịch từ Traditional Software Development sang AI-Driven Development.\nCác nguyên tắc cốt lõi trong phát triển phần mềm khi áp dụng AI: tính minh bạch, khả năng kiểm chứng, và sự kết hợp giữa con người và mô hình AI.\nAI-Augmented Engineer: mô hình lập trình viên sử dụng AI để tăng năng suất và giảm thời gian phát triển.\nNhững thách thức trong doanh nghiệp Việt Nam khi áp dụng AI vào Software Engineering: quy trình, chất lượng đầu ra, và khả năng tích hợp vào hệ thống hiện tại.\nPillar 1 — AI-Driven Development Life Cycle overview and Amazon Q Developer demonstration Giới thiệu chi tiết AI-Driven SDLC gồm các giai đoạn: phân tích yêu cầu, thiết kế, sinh mã nguồn, kiểm thử tự động, triển khai và cải thiện liên tục.\nAmazon Q Developer:\nTự động sinh mã theo đặc tả kỹ thuật. Gợi ý sửa lỗi, phân tích log và đề xuất cải thiện. Sinh test cases và tài liệu tự động. Hỗ trợ sinh kiến trúc và code liên quan đến AWS services. Mini Demo: sử dụng Amazon Q Developer để tạo API, viết code backend, sinh unit test và tối ưu mã trong thời gian thực.\nPillar 2 — Kiro Demonstation Giới thiệu Kiro – trợ lý AI dành cho quy trình Software Engineering trong doanh nghiệp.\nPhát hiện và hỗ trợ liên tục:\nPhân tích backlog, tài liệu yêu cầu và quy trình Agile. Gợi ý kiến trúc, giải pháp kỹ thuật và user stories. Tối ưu quy trình phát triển giữa Dev – QA – Ops. Tự động hóa quy trình:\nSinh yêu cầu kỹ thuật (Technical Specification). Đề xuất cải thiện codebase và quy trình CI/CD. Hỗ trợ theo dõi tiến độ và phát hiện điểm nghẽn. Mini Demo: sử dụng Kiro để phân tích yêu cầu và sinh tài liệu thiết kế cũng như kế hoạch phát triển.\nTổng kết \u0026amp; Q\u0026amp;A Tổng kết 2 pillar: cách AI hỗ trợ toàn bộ vòng đời phát triển phần mềm từ phân tích đến triển khai.\nNhững thách thức phổ biến trong doanh nghiệp Việt Nam: phụ thuộc AI quá mức, chất lượng đầu ra không đồng nhất, yêu cầu năng lực đánh giá của lập trình viên.\nLộ trình học tập: Amazon Q Developer, AWS AI Practitioner, Developer Associate, và các khóa học chuyên sâu về GenAI trong Software Engineering.\nNhững Gì Học Được Tổng Quan về AI-Driven Development Hiểu rõ cách AI đang tái định hình quy trình phát triển phần mềm hiện đại, từ phân tích yêu cầu đến triển khai và bảo trì. Nhận thức được mô hình “AI-Augmented Engineer” – nơi AI hỗ trợ lập trình viên tăng tốc độ phát triển, đảm bảo chất lượng và giảm lỗi. Amazon Q Developer Sử dụng Amazon Q Developer để sinh mã nguồn từ mô tả, giúp tăng tốc độ coding và giảm thời gian viết các đoạn mã lặp lại. Tìm hiểu cách Q Developer hỗ trợ đọc hiểu codebase, đề xuất refactor, sinh test cases và phân tích lỗi. Thực hành mini-demo về sinh API, xử lý backend logic và tự động tạo test bằng AI. Kiro và Quy Trình Phát Triển Hiểu cách Kiro hỗ trợ đội ngũ kỹ thuật quản lý vòng đời phát triển: lập kế hoạch, phân tích yêu cầu, sinh tài liệu và đề xuất kiến trúc. Quan sát demo Kiro phân tích backlog, sinh user stories và tự động đề xuất giải pháp kỹ thuật phù hợp. Nhận thức được việc dùng AI để cải thiện sự phối hợp giữa Dev – QA – Ops. Vòng Đời AI-Driven Software Development Nắm được các giai đoạn chính: Requirement → Design → Coding → Testing → Deployment → Improvement và vai trò AI ở từng phần. Tìm hiểu cách AI hỗ trợ kiểm thử tự động và theo dõi chất lượng phần mềm liên tục. Ứng Dụng Vào Công Việc Áp dụng AI để viết code nhanh hơn, giảm lỗi và tăng hiệu quả khi triển khai tính năng mới. Sử dụng các công cụ như Q Developer để phân tích log, debug và tối ưu hóa hiệu suất code. Tăng năng suất trong việc viết tài liệu kỹ thuật (design docs, user stories) bằng AI. Tự động hóa các công việc tốn thời gian như refactor, viết test, và hỗ trợ review code. Trải Nghiệm Trong Sự Kiện Trải nghiệm trực tiếp các demo thực hành từ Amazon Q Developer và Kiro giúp hiểu rõ ứng dụng AI trong thực tế. Học hỏi từ chuyên gia AWS về những xu hướng Software Engineering hiện đại kết hợp với GenAI. Kết nối và trao đổi với cộng đồng lập trình viên đang áp dụng AI vào công việc tại Việt Nam. Kết luận Sự kiện “AI-Driven Development Life Cycle: Reimagining Software Engineering” giúp tôi hiểu sâu hơn về việc ứng dụng AI vào phát triển phần mềm. Với Amazon Q Developer và Kiro, lập trình viên có thể tăng tốc độ xây dựng sản phẩm, cải thiện chất lượng code và tối ưu hóa toàn bộ vòng đời phát triển phần mềm.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Hiểu cơ bản EC2 , triển khai kết nối thành công, và nắm các dịch vụ mạng AWS .\nTuần 3: Hiểu dịch vụ Compute VM AWS và triển khai thành công AWS Backup, File Storage Gateway, S3 bucket và Autoscaling Group.\nTuần 4: Hiểu dịch vụ lưu trữ AWS,thực hành VM Import/Export và triển khai File Storage Gateway, hoàn tất worklog và thống nhất ý tưởng project.\nTuần 5: Hiểu các dịch vụ bảo mật AWS và hoàn thành lab tối ưu chi phí EC2 và quản lý tài nguyên.\nTuần 6: Hoàn thành các lab IAM , nắm cơ bản AWS KMS và tìm hiểu các dịch vụ cơ sở dữ liệu AWS .\nTuần 7: Hoàn thành lab module 6 (RDS và di dời CSDL) và tiến triển trong nghiên cứu, triển khai project nhóm.\nTuần 8: trong quá trình ôn tập chuẩn bị cho kiểm tra giữa kỳ.\nTuần 9: ôn tập và hoàn thành bài kiểm tra giữa kỳ.\nTuần 10: Tiếp tục tiến triển trong nghiên cứu và thực hiện project nhóm.\nTuần 11: Tiếp tục tiến triển trong nghiên cứu và thực hiện project nhóm.\nTuần 12: Tiếp tục tiến triển trong nghiên cứu và thực hiện project nhóm.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Tìm hiểu về dịch vụ Compute VM trên AWS. Thực hành với dịch vụ Compute VM trên AWS. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về dịch vụ Compute VM trên AWS. + Amazon Elastic Compute Cloud (EC2) + Amazon Lightsail + Amazon EFS / FSX + AWS Application Migration Service (MGN) 15/09/2025 16/09/2025 https://www.youtube.com/watch?v=-t5h4N6vfBs\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=72 3 - Tìm hiểu về dịch vụ Compute VM trên AWS. + Amazon Elastic Compute Cloud (EC2) + Amazon Lightsail + Amazon EFS / FSX + AWS Application Migration Service (MGN) 15/09/2025 16/09/2025 https://www.youtube.com/playlist?list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i 4 - Thực hành: + Triển khai AWS Backup cho hệ thống + Triển khai AWS File Storage Gateway + Tạo S3 bucket + Triển khai Autoscaling Group 17/09/2025 19/09/2025 https://000013.awsstudygroup.com/vi 5 - Thực hành: + Triển khai AWS Backup cho hệ thống + Triển khai AWS File Storage Gateway + Tạo S3 bucket + Triển khai Autoscaling Group 17/09/2025 19/09/2025 https://000024.awsstudygroup.com 6 - Thực hành: + Triển khai AWS Backup cho hệ thống + Triển khai AWS File Storage Gateway + Tạo S3 bucket\n+ Triển khai Autoscaling Group 17/09/2025 19/09/2025 https://000024.awsstudygroup.com Kết quả đạt được tuần 3: Hiểu rõ về dịch vụ Compute VM trên AWS:\nAmazon Elastic Compute Cloud (EC2): Amazon EC2 giống với máy chủ ảo hoặc máy chủ vật lý truyền thống. EC2 có khả năng khởi tạo nhanh, khả năng co dãn tài nguyên mạnh mẽ, linh hoạt. Amazon Lightsail: là dịch vụ tính toán có chi phí thấp (giá tính theo tháng chỉ bắt đầu từ 3,5 $ / tháng ) ngoài ra mỗi Instance Lightsail tạo ra cũng sẽ có một mức data transfer đi kèm. (data transfer này có mức giá rẻ hơn data transfer từ EC2 tương đối nhiều), phù hợp cho các workload nhẹ , môi trường test dev, không yêu cầu tải CPU cao liên tục \u0026gt; hơn 2 giờ mỗi ngày. Amazon EFS / FSX: EFS ( Elastic File System ) cho phép tạo các NFSv4 Network volume và gán vào nhiều EC2 Instances cùng lúc, quy mô lưu trữ lên đến hàng petrabyte. EFS chỉ support Linux. Sử dụng EFS chỉ tính chi phí theo dung lượng sử dụng,có thể được cấu hình để mount vào môi trường on-premise qua DX hoặc VPN. FSx cho phép tạo các NTFS volume và gán vào nhiều EC2 Instances cùng lúc sử dụng giao thức SMB (Server Message Block), support Windows và Linux, chỉ tính chi phí theo dung lượng sử dụng AWS Application Migration Service: dùng để migrate và replicate phục vụ mục đích xây dựng Disaster Recovery Site cho các máy chủ thực, ảo lên môi trường AWS, liên tục sao chép các máy chủ nguồn sang EC2 Instance trên tài khoản AWS (asynchronous / synchronous ). Thành công triển khai AWS Backup, File Storage Gateway và Autoscaling group.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Suy nghĩ và họp nhóm về ý tưởng project. Học về dịch vụ lưu trữ trên AWS Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu dịch vụ lưu trữ trên AWS. + Amazon Simple Storage Service - S3 + Amazon Storage Gateway + Snow Family + Disaster Recovery on AWS emsp; + AWS Backup 22/09/2025 23/09/2025 https://www.youtube.com/watch?v=hsCfP0IxoaM\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=103 3 - Tìm hiểu dịch vụ lưu trữ trên AWS. + Amazon Simple Storage Service - S3 + Amazon Storage Gateway + Snow Family + Disaster Recovery on AWS emsp; + AWS Backup 22/09/2025 23/09/2025 https://www.youtube.com/watch?v=mPBjB6Ltl_Q\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=105 4 - Làm Lab về dịch vụ lưu trữ trên AWS Thực hành: + VM Import/Export + Triển khai File Storage Gateway 24/09/2025 25/09/2025 https://000014.awsstudygroup.com/vi https://000024.awsstudygroup.com/vi 5 - Làm Lab về dịch vụ lưu trữ trên AWS Thực hành: + VM Import/Export + Triển khai File Storage Gateway 24/09/2025 25/09/2025 https://000014.awsstudygroup.com/vi https://000024.awsstudygroup.com/vi 6 - họp nhóm về ý tưởng project và viết worklog 26/09/2025 26/09/2025 Kết quả đạt được tuần 4: biết được dịch vụ lưu trữ trên AWS là gì:\nAmazon Simple Storage Service - S3 Amazon Storage Gateway Snow Family Disaster Recovery on AWS Thành công import/export VM và triển Khai File Storage Gateway\nHoàn thành viết worklog và thống nhất chung project\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Tìm hiểu về các dịch vụ bảo mật trên AWS. Làm lab. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về các dịch vụ bảo mật trên AWS. + Shared Responsibility Model - AWS Identity and Access Management + Amazon Cognito + AWS Organization \u0026amp; AWS Identity Center ( SSO ) + AWS KMS 29/09/2025 30/09/2025 https://www.youtube.com/watch?v=tsobAlSg19g\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=150 3 - Tìm hiểu về các dịch vụ bảo mật trên AWS. + Shared Responsibility Model - AWS Identity and Access Management + Amazon Cognito + AWS Organization AWS Identity Center ( SSO ) + AWS KMS 29/09/2025 30/09/2025 https://www.youtube.com/watch?v=tsobAlSg19g\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=150 4 Thực hành: + Làm lab 18 về AWS Security Hub 01/10/2025 01/10/2025 https://000018.awsstudygroup.com/vi 5 Thực hành: + Làm lab 22 \u0026amp; 27 về tối ưu chi phí EC2 với Lambda và quản lý tài nguyên bằng Tag và Resource Groups 02/10/2025 03/10/2025 https://000027.awsstudygroup.com/vi 6 Thực hành: + Làm lab 22 \u0026amp; 27 về tối ưu chi phí EC2 với Lambda và quản lý tài nguyên bằng Tag và Resource Groups 02/10/2025 03/10/2025 https://000027.awsstudygroup.com/vi Kết quả đạt được tuần 5: Hiểu được về các dịch vụ bảo mật trên AWS:\nShared Responsibility Model: là mô hình bảo mật của AWS, xác định trách nhiệm giữa AWS và khách hàng trong việc bảo vệ hệ thống và dữ liệu trên nền tảng đám mây AWS Identity and Access Management: quản lý danh tính người dùng, vai trò và quyền truy cập để kiểm soát an toàn việc truy cập vào tài nguyên AWS. Amazon Cognito: cung cấp tính năng xác thực, phân quyền và quản lý người dùng cho các ứng dụng web và di động. AWS Organization \u0026amp; AWS Identity Center ( SSO ): cho phép quản lý tập trung nhiều tài khoản AWS, kiểm soát truy cập thống nhất và đăng nhập một lần cho người dùng trong toàn tổ chức. AWS KMS: quản lý các khóa mã hóa dùng để bảo vệ dữ liệu, hỗ trợ tạo, lưu trữ và kiểm soát khóa một cách an toàn. Nắm được cấu trúc về AWS Security Hub.\nHoàn tất làm xong bài Lab 22 \u0026amp; 27.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Tiếp tục làm các bài lab của module 5 Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Thực hành: + Làm lab 28 về Quản lý truy cập vào dịch vụ EC2 Resource Tag với AWS IAM 06/10/2025 06/10/2025 https://000028.awsstudygroup.com/vi 3 Thực hành: + Làm lab 30 \u0026amp; 33 về giới hạn quyền của User với IAM PERMISSION BOUNDARY và Mã hóa ở trạng thái lưu trữ với AWS KMS 07/10/2025 07/10/2025 https://000030.awsstudygroup.com/vi https://000033.awsstudygroup.com/vi 4 Thực hành: + Làm lab 44 \u0026amp; 48 về IAM Role \u0026amp; Condition và Cấp quyền cho ứng dụng truy cập dịch vụ AWS với IAM Role 08/10/2025 08/10/2025 https://000044.awsstudygroup.com/vi https://000048.awsstudygroup.com/vi 5 - Tìm hiểu về dịch vụ Cơ sở dữ liệu trên AWS: + Database Concepts + Amazon RDS + Amazon Aurora + Amazon RedShift + Amazon ElastiCache 09/10/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ https://www.youtube.com/watch?v=OOD2RwWuLRw\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=217 6 - Họp nhóm vẽ sơ đồ Diagram 10/10/2025 10/10/2025 Kết quả đạt được tuần 6: Biết cách quản lý truy cập vào dịch vụ EC2 Resource Tag với AWS IAM Thành công làm lab 30 \u0026amp; 33, nắm được về giới hạn quyền của User với IAM PERMISSION BOUNDARY và Mã hóa ở trạng thái lưu trữ với AWS KMS Hiểu thêm về IAM Role \u0026amp; Condition và Cấp quyền cho ứng dụng truy cập dịch vụ AWS với IAM Role Có thêm kiến thức về dịch vụ Cơ sở dữ liệu trên AWS: Database Concepts Amazon RDS: Là dịch vụ cơ sở dữ liệu quan hệ được quản lý, hỗ trợ nhiều hệ quản trị cơ sở dữ liệu như MySQL, PostgreSQL, MariaDB, Oracle và SQL Server. Dịch vụ tự động hóa các tác vụ như sao lưu, vá lỗi và mở rộng quy mô. Amazon Aurora: Là cơ sở dữ liệu quan hệ hiệu năng cao, hoàn toàn được quản lý, tương thích với MySQL và PostgreSQL, được thiết kế để đảm bảo khả năng mở rộng và tính sẵn sàng cao. Amazon RedShift: Là dịch vụ kho dữ liệu (data warehouse) được quản lý toàn diện, tối ưu cho xử lý phân tích dữ liệu quy mô lớn (OLAP) và phân tích dữ liệu lớn (Big Data Analytics). Amazon ElastiCache: Là dịch vụ bộ nhớ đệm trong RAM được quản lý, hỗ trợ Redis và Memcached, giúp cải thiện hiệu năng ứng dụng bằng cách giảm tải và độ trễ truy vấn cơ sở dữ liệu. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Làm các bài lab từ module 6. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Thực hành Lab module 6: + Làm Lab 5 về về Amazon Relational Database Service (Amazon RDS) + Làm lab 43 về chuyển đổi lược đồ và di dời CSDL 13/10/2025 14/10/2025 https://000005.awsstudygroup.com/vi https://000043.awsstudygroup.com/vi 3 Thực hành Lab module 6: + Làm Lab 5 về về Amazon Relational Database Service (Amazon RDS) + Làm lab 43 về chuyển đổi lược đồ và di dời CSDL 13/10/2025 14/10/2025 https://000005.awsstudygroup.com/vi https://000043.awsstudygroup.com/vi 4 - Nghiên cứu và làm project nhóm 15/10/2025 17/10/2025 5 - Nghiên cứu và làm project nhóm 15/10/2025 17/10/2025 6 - Nghiên cứu và làm project nhóm 15/10/2025 17/10/2025 Kết quả đạt được tuần 7: Thành công làm xong bài lab module 6\nĐang có tiến triển tốt trong Nghiên cứu và làm project nhóm\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: ôn bài để chuẩn bị cho kiểm tra giữa kì Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn lại kiến thức để chuẩn bị cho bài giữa kì 20/10/2025 24/10/2025 3 - Ôn lại kiến thức để chuẩn bị cho bài giữa kì 20/10/2025 24/10/2025 4 - Ôn lại kiến thức để chuẩn bị cho bài giữa kì 20/10/2025 24/10/2025 5 - Ôn lại kiến thức để chuẩn bị cho bài giữa kì 20/10/2025 24/10/2025 6 - Ôn lại kiến thức để chuẩn bị cho bài giữa kì 20/10/2025 24/10/2025 Kết quả đạt được tuần 8: Vẫn còn trong quá trình ôn tập. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Ôn bài và làm bài giữa kì. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn lại kiến thức để chuẩn bị cho bài giữa kì 27/10/2025 29/10/2025 3 - Ôn lại kiến thức để chuẩn bị cho bài giữa kì 27/10/2025 29/10/2025 4 - Ôn lại kiến thức để chuẩn bị cho bài giữa kì 27/10/2025 29/10/2025 5 - Làm bài kiểm tra giữa kỳ 30/10/2025 30/10/2025 6 - Nghiên cứu và làm project nhóm 31/10/2025 31/10/2025 Kết quả đạt được tuần 9: Ôn bài xong và hoàn thành bài giữa kỳ "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 15/09/2025 15/09/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 16/09/2025 16/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 17/09/2025 17/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 18/09/2025 18/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 19/09/2025 19/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 2: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về dự án Workshop này trình bày kiến trúc và cách triển khai ứng dụng web English Journey –\nmột website học tiếng Anh được xây dựng trên nền tảng AWS.\nỨng dụng cho phép người học:\nĐăng ký / đăng nhập an toàn, Làm bài kiểm tra trình độ (A1–C1) trước khi bắt đầu học, Luyện từ vựng,bài đọc và làm quiz, Theo dõi quá trình học của bản thân. Về mặt hạ tầng, dự án minh họa cách kết hợp nhiều dịch vụ managed của AWS:\nAWS Amplify làm nền tảng trung tâm cho backend và hosting của web app, Amazon Cognito cho xác thực người dùng, AWS Lambda cho nghiệp vụ backend (Level Test, Quiz, Vocabulary), Amazon DynamoDB cho dữ liệu ứng dụng, Amazon SES để gửi email thông báo ( xác thực tài khoản ), Amazon CloudWatch cho log, metric, AWS WAF để bảo vệ web trước một số tấn công phổ biến, cùng IAM Roles \u0026amp; Policies để kiểm soát quyền truy cập giữa các thành phần. Mục tiêu của workshop Sau khi đọc phần workshop, người đọc có thể:\nHiểu kiến trúc tổng thể của ứng dụng English Journey trên AWS. Giải thích vai trò của Amplify trong việc điều phối Cognito, Lambda, DynamoDB và Route53. Mô tả được luồng xử lý của tính năng kiểm tra trình độ, từ frontend → Lambda → DynamoDB. Hiểu cách thông báo được gửi qua email bằng Amazon SES. Nhận thức tầm quan trọng của CloudWatch, IAM và WAF đối với giám sát và bảo mật. Tổng quan về workshop Dự án này tận dụng các dịch vụ của AWS để xây dựng và triển khai ứng dụng:\n- WS Amplify: Dịch vụ hosting cho phép triển khai ứng dụng nhanh chóng và dễ dàng. - AWS Lambda: Xử lý các tác vụ, backend và logic của ứng dụng mà không cần quản lý máy chủ, giúp tiết kiệm chi phí và tài nguyên. - Amazon DynamoDB: Cơ sở dữ liệu NoSQL dùng để lưu trữ dữ liệu người dùng, từ vựng và kết quả học tập. - Amazon CloudWatch: Giám sát hiệu suất và hoạt động của ứng dụng, cung cấp log và dễ dàng kiểm tra khi có sự cố. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lê Tấn Lực\nSố điện thoại: 0379784509\nEmail: lucltse184288@fpt.edu.vn\nTrường: Đại học FPT TP.HCM\nNgành: An toàn thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 08/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Migration \u0026amp; Modernization\nTối ưu hóa chi phí điện toán đám mây: Cẩm nang Rehost Migration (Phần 4 – Di trú: Hiện thực hóa kế hoạch tiết kiệm chi phí) Tác giả: Dan Krueger, James Gaines, và Rohit Vaitheeswaran – 31/03/2025\nChuyên mục: AWS Cloud Financial Management, AWS Compute Optimizer, AWS Cost Explorer, Best Practices, Billing \u0026amp; Account Management, Cloud Cost Optimization, Customer Enablement, Enterprise Strategy, Thought Leadership\nBài viết này là phần thứ tư trong chuỗi bốn phần hướng dẫn từng bước cách tối ưu chi phí trong suốt quá trình Rehost migration trên AWS, cụ thể:\nKhám phá các thành phần chi phí và môi trường on-premises. Xây dựng business case chính xác trong giai đoạn assess. Hiểu và kiểm soát chi tiêu trên cloud trong giai đoạn mobilize. Tối ưu chi phí để đạt được các khoản tiết kiệm tài chính đã hoạch định trong giai đoạn migrate. Hình 1: Tổng quan hoạt động chi phí của quá trình Rehost Migration theo từng giai đoạn\n1. Tối ưu chi phí trên AWS: Chúng tôi sử dụng các dịch vụ AWS và công cụ cụ thể trong suốt quá trình Rehost migration để tối ưu hóa chi phí.\nCác dịch vụ AWS này cung cấp đề xuất giúp tối ưu chi phí Amazon EC2 instances, chi phí lưu trữ (storage costs), và chi phí vận hành ứng dụng tổng thể (overall application run cost). Khoản tiết kiệm chi phí có thể tăng thêm vì quá trình migration và tối ưu hóa ban đầu được thực hiện dựa trên application performance metrics từ on-premises data center (bao gồm CPU, memory, disk I/O, và network). Việc tối ưu chi phí sau khi di trú (post-migration cost optimization) yêu cầu phân tích các số liệu sử dụng, vốn khác nhau tùy thuộc vào loại và kích cỡ của instance.\n1.1. Trang chủ AWS Billing and Cost Management AWS Billing and Cost Management cung cấp các dịch vụ quan trọng để tối ưu chi phí trong suốt quá trình Rehost migration.\nNếu bạn đang sử dụng tổ chức AWS (AWS Organizations) với quản lí tài khoản (management account) để quản trị tập trung môi trường AWS, hãy cấu hình tài khoản thành viên (member accounts) truy cập các dịch vụ này theo nhu cầu và chính sách truy cập của tổ chức. Các dịch vụ này được áp dụng cho nhiều nhóm làm việc khác, không chỉ riêng các cost management stakeholders được chỉ định. AWS Billing and Cost Management console cung cấp thông tin tóm tắt, cho phép account owner có thể đi sâu vào từng danh mục cụ thể (specific category).\nLanding page bao gồm các default widgets, cung cấp cái nhìn nhanh (quick view) về dự báo chi phí hiện tại (current forecast) so với các chi phí trong vài tháng gần đây.\nInfo tab hiển thị bản tóm tắt chi tiết (detailed summary) và giải thích nội dung mà mỗi widget cung cấp cho account owner.\nCác tiện ích mặc định trong AWS Billing and Cost Management console bao gồm:\nTóm tắt chi phí (Cost Summary) – Hiển thị xu hướng chi tiêu hiện tại so với mức chi của tháng trước. Các chi phí hiển thị tại đây không bao gồm khoản tín dụng và chiết khấu nào. Giám sát chi phí (Cost Monitor) – Hiển thị chi phí, ngân sách và các bất thường về chi phí được AWS phát hiện. Trạng thái bất thường về chi phí trong giám sát chi phí (Cost Monitor) được xác định dựa trên cấu hình trong giám sát chi phí (Cost Monitor), thuộc tab phát hiện chi phí bất thường (Cost Anomaly Detection). Phân tích chi phí (Cost Breakdown) – Bảng phân tích chi phí trong 6 tháng gần nhất để giúp hiểu rõ xu hướng và yếu tố chi phí. Nhóm chi phí theo các chỉ số như dịch vụ AWS, tài khoản thành viên, vùng, thẻ phân bố chi phí, và danh mục chi phí. Hành động đề xuất (Recommended Actions) – Cung cấp hướng dẫn cho chủ tài khoản AWS nhằm tuân thủ các thực tiễn quản lí tài chính đám mây (AWS cloud financial management best practices) và tối ưu chi phí dựa trên các đề xuất được đưa ra. Cơ hội tiết kiệm (Savings Opportunities) – Đưa ra các đề xuất từ trung tâm tối ưu hóa chi phí (Cost Optimization Hub) trong nhiều danh mục khác nhau, chẳng hạn như điều chỉnh kích thước, các loại phiên bản khác nhau, và khuyến nghị xóa bỏ các tài nguyên không được sử dụng trong tài khoản. 1.2. AWS Cost Explorer Tiện ích phân tích chi phí (Cost Breakdown widget) có thể mở rộng sang AWS Cost Explorer, cho phép chủ tài khoản và nhóm quản lý chi phí trực quan hóa, phân tích và quản lý chi tiêu trên AWS.\nAWS Cost Explorer cung cấp các góc nhìn tổng quát và chi tiết về xu hướng chi tiêu. Lọc và dự báo để xác định các yếu tố chi phí và sự bất thường. Người dùng có thể tùy chỉnh báo cáo theo khoảng thời gian (giờ, ngày, tháng) và nhóm theo dịch vụ. Người dùng có thể lưu báo cáo trong thư viện để sử dụng lại trong tương lai.\n1.3. Trung tâm tối ưu hóa chi phí AWS (AWS Cost Optimization Hub) Trung tâm tối ưu chi phí AWS (AWS Cost Optimization Hub) cung cấp cái nhìn tổng quan về các cơ hội tối ưu hóa chi phí cho các EC2 instances đã được migrate.\nHình 2: Trung tâm Tối ưu Chi phí và Các Khuyến nghị\nSau khi quá trình Rehost migration hoàn tất, hệ thống đưa ra khuyến nghị chuyển sang sử dụng Graviton instances để đạt được mức tiết kiệm chi phí bổ sung.\nNgoài ra, dựa trên các chỉ số sử dụng CPU và bộ nhớ, trung tâm tối ưu chi phí (Cost Optimization Hub) cũng sẽ đề xuất điều chỉnh kích thước phù hợp cho các instance, cũng như xóa bỏ những tài nguyên đang không hoạt động.\nKhai thác trung tâm tối ưu chi phí (Cost Optimization Hub) giúp đội ngũ quản lý chi phí xác định, ưu tiên và triển khai các biện pháp tiết kiệm hiệu quả hơn, nâng cao quản lí tài chính đám mây, tối ưu hóa tài nguyên và mức tiết kiệm chi phí bổ sung ngoài phần tiết kiệm đã đạt được trong quá trình migration lên AWS.\n1.4. Trình tối ưu hóa tính toán AWS (AWS Compute Optimizer) AWS Compute Optimizer giúp giảm chi phí EC2 instances thông qua các đề xuất kích thước phù hợp. Công cụ này cung cấp tổng quan tiết kiệm, nâng cao hiệu năng và đề xuất tối ưu hóa theo từng vùng cho các tài nguyên sau:\nAmazon EC2 Amazon EC2 Auto Scaling Groups Amazon EBS AWS Lambda functions Amazon ECS on AWS Fargate Commercial software licenses Amazon RDS DB instances and storage Khi bật Compute Optimizer, AWS sẽ đánh giá tài nguyên bằng cách xem xét thông số kĩ thuật và mô hình sử dụng được ghi lại bởi Amazon CloudWatch trong 14 ngày gần nhất, bao gồm các chỉ số như mức sử dụng CPU, truyền mạng, hoạt động đĩa, mức độ sử dụng instance hiện tại.\n2. Kết luận Thiết lập quyền sở hữu chuyên trách và triển khai quy trình giám sát chi phí có hệ thống bằng cách sử dụng AWS Cost Explorer, AWS Budgets, và AWS Cost and Usage Reports.\nCác công cụ này, khi được kết hợp với AWS Cost Optimization Hub và AWS Compute Optimizer, cung cấp các khuyến nghị hành động cho EC2 instances, bộ lưu trữ, và tối ưu hóa ứng dụng. Việc phân tích thường xuyên các mô hình sử dụng tài nguyên và triển khai các khuyến nghị về điều chỉnh kích thước giúp duy trì hiệu quả chi phí lâu dài, vượt ra ngoài khoản tiết kiệm ban đầu trong quá trình migration, tạo nên nền tảng cho việc tối ưu chi phí liên tục.\nTrong bài viết này, chúng ta đã kết thúc hành trình tối ưu chi phí Rehost migration trong giai đoạn migrate bằng cách:\nXem xét các dịch vụ có sẵn trong 1.1 AWS Billing and Cost Management Home; Sử dụng 1.2 AWS Cost Explorer để trực quan hóa và phân tích chi phí; Và xem xét 1.3 AWS Cost Optimization Hub cùng 1.4 AWS Compute Optimizer để nhận các khuyến nghị chi tiết về tối ưu chi phí và cơ hội điều chỉnh quy mô. Chuỗi Blog Liên kết trực tiếp đến từng bài viết trong chuỗi như sau:\nPhần 1: Assess – Explore Cost Components Phần 2: Assess – Build a Business Case Phần 3: Mobilize – Understand and Control Cloud Spend Phần 4: Migrate – Realizing Planned Savings Tài nguyên bổ sung Liên hệ với chuyên gia migration của AWS để trao đổi về cách chúng tôi có thể hỗ trợ tổ chức của bạn.\nĐã sẵn sàng migrate và tối ưu hóa chi phí? Dưới đây là một số tài nguyên bổ sung:\nXem qua AWS Cloud Financial Management Guide để điều chỉnh các quy trình tài chính của bạn, giúp chúng sẵn sàng cho môi trường cloud. Khám phá những nội dung mới nhất trong AWS Cloud Financial Management. Tìm hiểu thêm về cách thực hiện migration và hiện đại hóa với AWS. Hãy khám phá Amazon Q Developer — một trợ lý được hỗ trợ bởi AI (AI-powered assistant), giúp bạn chuyển đổi các workload .NET, mainframe, VMware, và Java, vượt ra ngoài mô hình Rehost truyền thống. Giới thiệu tác giả Dan Krueger – Senior Customer Solutions Manager tại Amazon Web Services, có nhiều kinh nghiệm phục vụ khách hàng thuộc Chính phủ Liên bang Hoa Kỳ. Tại AWS, ông đã dẫn dắt nhiều dự án cloud migration quy mô lớn, giúp các cơ quan nâng cao năng lực thực thi nhiệm vụ. Trước đó, khi còn làm Program Executive tại IBM, Dan tập trung vào hiện đại hóa nền tảng dữ liệu và triển khai các giải pháp công nghệ phức tạp cho khách hàng chính phủ.\nJames Gaines – Senior Solutions Architect trong lĩnh vực Healthcare and Life Sciences tại AWS. Ông có nền tảng làm việc trong các môi trường có quy định nghiêm ngặt như Department of Defense và pharmaceutical industry. James sở hữu toàn bộ AWS Certifications và chuyên về cloud migrations, application modernization, cùng phân tích nâng cao để thúc đẩy đổi mới trong lĩnh vực y tế và khoa học đời sống.\nRohit Vaitheeswaran – Senior Solutions Architect tại AWS, chuyên về Healthcare and Life Sciences. Ông có kinh nghiệm đa ngành, từng dẫn dắt nhiều dự án migration strategy và cloud optimization initiatives quy mô lớn. Trong suốt sự nghiệp, Rohit đã giúp các tổ chức thuộc Financial Services, Fintech, và Healthcare tối ưu hành trình lên cloud của họ trên AWS, đặc biệt tập trung vào migration strategy và cost optimization, giúp khách hàng tối đa hóa khoản đầu tư cloud và tuân thủ các yêu cầu đặc thù của ngành.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "AWS DevOps \u0026amp; Developer Productivity Blog\nKhám phá AWS Console: Chẩn đoán lỗi với Amazon Q Developer Tác giả: Marco Frattallone, Matthias Seeger, và Surabhi Tandon — Ngày 10 tháng 1 năm 2025\nDanh mục: Amazon Q, Amazon Q Developer, AWS Management Console, DevOps, Intermediate (200)\nGiới thiệu Các Developers, IT Operators, và trong một số trường hợp là Site Reliability Engineers (SREs), chịu trách nhiệm triển khai và vận hành hạ tầng cùng ứng dụng, đồng thời xử lý và khắc phục sự cố một cách hiệu quả và kịp thời. Quản lý sự cố hiệu quả đòi hỏi chẩn đoán nhanh, phân tích nguyên nhân gốc rễ, và thực hiện hành động khắc phục. Việc xác định nguyên nhân gốc có thể rất phức tạp trong các hệ thống hiện đại, vốn bao gồm nhiều tài nguyên được triển khai phân tán trên nhiều môi trường khác nhau. Amazon Q Developer, một trợ lý được hỗ trợ bởi AI tạo sinh, có thể đơn giản hóa quy trình này bằng cách chẩn đoán các lỗi xuất hiện trong AWS Management Console.\nAmazon Q Developer giúp bạn tiết kiệm thời gian quan trọng khi xử lý sự cố production, bằng cách hỗ trợ chẩn đoán lỗi liên quan đến môi trường AWS của bạn. Những lỗi này có thể bắt nguồn từ các sai cấu hình giữa nhiều tài nguyên khác nhau, thường yêu cầu bạn chuyển qua lại giữa nhiều console của các dịch vụ AWS để tìm nguyên nhân gốc. Amazon Q Developer sử dụng generative AI để tự động hóa quá trình chẩn đoán lỗi phát sinh trong giao diện AWS Console, giúp giảm Mean Time To Repair (MTTR) và hạn chế tối đa tác động của sự cố lên hoạt động kinh doanh.\nBài viết này sẽ giải thích cách Amazon Q Developer hỗ trợ chẩn đoán lỗi trong AWS Console khi làm việc với các dịch vụ AWS được hỗ trợ. Đồng thời mô tả cách tính năng này hoạt động nhằm hướng dẫn bạn trong quá trình khắc phục sự cố. Chúng tôi cũng sẽ phân tích phía sau hậu trường để cho thấy các quy trình vận hành giúp kích hoạt và hỗ trợ tính năng này.\nChẩn đoán với Amazon Q Tính năng Diagnose with Amazon Q giúp chẩn đoán hầu hết các lỗi phổ biến xảy ra trong AWS Management Console đối với các dịch vụ AWS hiện đang được hỗ trợ bởi chức năng này. Tính năng này được kích hoạt khi người dùng có quyền phù hợp nhấn vào nút Diagnose with Amazon Q nằm cạnh thông báo lỗi. Amazon Q sẽ cung cấp giải thích bằng ngôn ngữ tự nhiên, trong đó phân tích nguyên nhân gốc rễ của lỗi. Sau đó, khi người dùng nhấn Help me resolve, Amazon Q sẽ hiển thị danh sách các bước hướng dẫn được sắp xếp theo thứ tự, giúp bạn khắc phục tình trạng lỗi. Sau khi hoàn thành, bạn có thể gửi phản hồi về việc giải pháp mà Amazon Q đưa ra có hữu ích hay không.\nVí dụ minh họa cho thấy cách Amazon Q Developer có thể giúp chẩn đoán lỗi khi khởi tạo instance trong Amazon EC2 và cung cấp hướng dẫn từng bước để xử lý lỗi đó.\nChẩn đoán với Amazon Q – Quyền IAM liên quan đến lỗi khởi tạo EC2 instance Phía sau hậu trường: Cách Amazon Q tạo chẩn đoán Để minh họa các khái niệm, chúng tôi sẽ trình bày phần giải thích trong bối cảnh hai ví dụ thực tế.\nVí dụ 1: Giả sử bạn cố gắng xóa một Amazon S3 bucket mà bucket đó không rỗng. Điều này dẫn đến thông báo lỗi:\nThis bucket is not empty. Buckets must be empty before they can be deleted. To delete all objects in the bucket, use the empty bucket configuration.\nVí dụ 2: Giả sử bạn cố gắng liệt kê các objects trong một S3 bucket cụ thể, nhưng thiếu AWS Identity and Access Management (IAM) permissions để thực hiện. Điều này dẫn đến thông báo lỗi:\nInsufficient permissions to list objects. After you or your AWS administrator has updated your permissions to allow the s3:ListBucket action, refresh the page. Learn more about Identity and access management in Amazon S3.\nKhi bạn nhấp vào nút Diagnose with Amazon Q bên cạnh thông báo lỗi trong AWS Management Console, Amazon Q sẽ tạo ra một phân tích (Analysis) diễn giải nguyên nhân gốc rễ của lỗi bằng ngôn ngữ tự nhiên. Bước này được hỗ trợ bởi mô hình ngôn ngữ lớn (LLMs). Thông tin ngữ cảnh được cung cấp cho LLM bao gồm thông báo lỗi hiển thị trong console, URL của hành động kích hoạt, và IAM role của người dùng đã đăng nhập vào AWS Console. Dịch vụ luôn hoạt động trong phạm vi quyền được cấp cho role của bạn khi bạn thao tác trong AWS Console, và các đặc quyền không bao giờ bị leo thang vượt quá những gì đã được gán cho bạn.\nKhi bạn nhấp vào nút Help me resolve sau khi đã xem xét phân tích, Amazon Q truy xuất thêm thông tin về trạng thái của các resources trong AWS Account nơi lỗi xảy ra. Ở giai đoạn này, hệ thống chủ động quyết định thông tin nào còn thiếu và phát sinh các yêu cầu thẩm vấn tới các dịch vụ nội bộ để đáp ứng nhu cầu thông tin. Việc thẩm vấn không cần thiết cho các lỗi đơn giản, như ví dụ 1 ở trên, nhưng trở nên thiết yếu để giải quyết các lỗi phức tạp hơn, khi thông tin từ ngữ cảnh không đủ.\nDựa trên ngữ cảnh, phân tích lỗi, quyền của người dùng, và kết quả thẩm vấn tài khoản, Amazon Q tạo ra các hướng dẫn Resolution theo từng bước. Bước này được hỗ trợ bởi LLMs.\nSau khi triển khai và xác thực các bước do Amazon Q cung cấp để giải quyết lỗi trong console, bạn có tùy chọn cung cấp phản hồi về trải nghiệm của mình.\nSơ đồ mô tả tương tác giữa Người dùng, AWS Console và Amazon Q Developer Thông tin ngữ cảnh Thông tin ngữ cảnh giúp các mô hình ngôn ngữ lớn (LLMs) tạo ra phản hồi chính xác và phù hợp hơn. Dữ liệu ngữ cảnh được tự động truyền vào Amazon Q từ giao diện AWS Console. Vì là cơ sở cho toàn bộ quá trình phân tích và ra quyết định, nên thông tin ngữ cảnh cần được cung cấp càng đầy đủ càng tốt. Ở mức tối thiểu, Amazon Q sẽ thu thập thông báo lỗi (error message), URL của hành động gây ra lỗi, và IAM role mà người dùng đăng nhập đang sử dụng.\nHệ thống sẽ tự động trích xuất các định danh (identifiers) có liên quan từ thông tin ngữ cảnh này.\nTrong ví dụ 1 đang chạy của chúng tôi, URL có thể là:\nhttps://s3.console.aws.amazon.com/s3/bucket/my-bucket-123456/delete?region=us-west-2, từ đó Amazon Q trích xuất aws_region = \u0026ldquo;us-west-2\u0026rdquo; và s3_bucket_name = \u0026ldquo;my-bucket-123456\u0026rdquo;.\nNgoài phần ngữ cảnh tối thiểu này, Amazon Q có thể thu thập thông tin bổ sung từ bảng điều khiển, liên quan đến những gì người dùng nhìn thấy trên màn hình khi lỗi xảy ra, chẳng hạn như nội dung trong các ô văn bản hoặc thành phần giao diện (widgets) trong giao diện hiện tại. Amazon Q cũng có thể sử dụng ngữ cảnh cụ thể do dịch vụ nền tảng cung cấp.\nTrong trường hợp ví dụ 2 ở trên, tên bucket được trích xuất từ URL, hành động s3:ListBucket từ thông báo lỗi, và Amazon Q có thể lấy thêm thông tin từ IAM về các chính sách liên quan cũng như các câu lệnh cho phép hoặc từ chối.\nThẩm vấn tài khoản người dùng đã đăng nhập Tính năng Diagnose with Amazon Q không chỉ thụ động nhận thông tin ngữ cảnh mà còn có khả năng chủ động truy vấn thêm thông tin. Amazon Q thực hiện các truy vấn chỉ đọc không thay đổi dữ liệu nhằm thu thập thêm ngữ cảnh về tài nguyên trong tài khoản AWS, trạng thái của các tài nguyên đó, và mối quan hệ giữa chúng với tài nguyên đang gặp lỗi. Ngữ cảnh về mối quan hệ này giúp mô hình LLM phân tích nguyên nhân gốc chính xác hơn khi chẩn đoán lỗi.\nAmazon Q thẩm vấn tài khoản người dùng đã đăng nhập bằng AWS Cloud Control API (CCAPI) để xác định các tài nguyên đang được triển khai trong tài khoản. Trong quá trình thiết lập ban đầu (onboarding) Amazon Q, chính sách được quản lý AmazonQFullAccess sẽ được gán cho vai trò IAM mà người dùng đang sử dụng. Chính sách này bao gồm cloudformation:ListResources và cloudformation:GetResource quyền IAM của CCAPI, cho phép truy cập vào các endpoint đọc (read) và liệt kê (list) của CCAPI. Nếu bạn không muốn gán chính sách được quản lý AmazonQFullAccess bạn có thể thêm cloudformation:ListResources và cloudformation:GetResource trực tiếp vào IAM Role.\nTrong ví dụ đơn giản ví dụ 1, nơi lỗi xảy ra do bucket S3 không trống, thông báo lỗi và URL trong bảng điều khiển đã chứa đầy đủ thông tin cần thiết để xử lý, nên không cần truy vấn thêm vào tài khoản AWS.\nNgược lại, với lỗi quyền IAM trong ví dụ 2, việc hiểu các quyền của IAM role gắn với tài nguyên gặp lỗi là rất hữu ích. Amazon Q có thể lấy thông tin về chính sách ở cấp danh tính (identity-level) cho role và chính sách ở cấp tài nguyên cho tài nguyên bị ảnh hưởng. Dựa trên đó, Amazon Q sẽ phân tích nguyên nhân của lỗi bằng cách sử dụng các dịch vụ IAM nội bộ.\nCụ thể, URL trong ví dụ 2 có thể là:\nhttps://s3.console.aws.amazon.com/s3/buckets/my-bucket-123456?region=us-west-2\u0026bucketType=general\u0026tab=objects\ntừ đó Amazon Q trích xuất được khu vực và tên S3 bucket. Nó cũng có thể trích xuất hành động s3:ListBucket trực tiếp từ thông báo lỗi. Dựa trên các thông tin này, Amazon Q có thể lấy các chính sách bucket cho my-bucket-123456 các chính sách cấp danh tính của vai trò đó, sau đó quét để kiểm tra xem có hay không của hành động s3:ListBucket hoặc gọi các dịch vụ nội bộ của IAM để thu thập thêm thông tin về nguyên nhân dẫn đến việc bị từ chối truy cập.\nAmazon Q chỉ hoạt động trong phạm vi quyền hạn được cấp bởi vai trò IAM của người dùng đã đăng nhập, đảm bảo rằng các đặc quyền không bao giờ bị mở rộng vượt quá những gì vai trò đó được gán. Amazon Q gọi CCAPI thay mặt cho người dùng đã đăng nhập, sử dụng đúng các quyền mà vai trò IAM của người dùng cho phép. CCAPI sẽ kế thừa quyền của người dùng và có cùng mức truy cập để truy vấn tài nguyên trong tài khoản của người dùng.\nTrong ví dụ 2, nếu người dùng đăng nhập không có quyền truy cập vào chính sách của bucket my-bucket-123456, thì Amazon Q cũng sẽ không thể truy cập được. Tất cả các lệnh gọi API đều được ghi lại trong CloudTrail, bao gồm việc Amazon Q gọi CCAPI, và CCAPI tiếp tục gọi đến các dịch vụ đích (ví dụ: S3, IAM) tùy thuộc vào yêu cầu.\nTạo hướng dẫn khắc phục theo từng bước Ở giai đoạn này, tất cả thông tin thu thập được được Amazon Q tổng hợp để tạo ra các hướng dẫn khắc phục hữu ích và khả thi theo từng bước. Để minh họa, dưới đây là các hướng dẫn mẫu cho các ví dụ đang xét. Khi các mô hình được cập nhật và cải tiến theo thời gian, các phản hồi có thể thay đổi.\nĐối với Ví dụ 1, các hướng dẫn mẫu có thể như sau:\nTruy cập S3 console, nhấp \u0026ldquo;Buckets\u0026rdquo; và chọn bucket my-bucket-123456. Nhấp vào tab \u0026ldquo;Empty\u0026rdquo;. Nếu bucket chứa số lượng lớn objects, việc tạo một lifecycle rule để xóa tất cả objects trong bucket có thể là cách hiệu quả hơn để làm rỗng bucket. Nhập \u0026ldquo;permanently delete\u0026rdquo; vào ô nhập văn bản và xác nhận rằng tất cả objects sẽ bị xóa. Thử xóa lại S3 bucket my-bucket-123456. Đối với Ví dụ 2, bạn có thể thực hiện:\nVào IAM console. Chỉnh sửa IAM policy đính kèm với role ReadOnly Cho phép hành động s3:ListBucket cho resource có ARN: arn:aws:s3:::my-bucket-123456 Lưu IAM policy đã được cập nhật. Làm mới trang S3 console để liệt kê objects trong bucket my-bucket-123456. Lưu ý rằng các hướng dẫn chứa thông tin được suy ra từ ngữ cảnh, chẳng hạn như tên bucket my-bucket-123456, thay vì các giá trị giữ chỗ (placeholders). Các hướng dẫn được trả về bởi Diagnose with Amazon Q là đầy đủ và chi tiết, đủ để người dùng có thể thực hiện mà không cần thêm bất kỳ bước bổ sung nào.\nTrên thực tế, mặc dù dịch vụ sử dụng LLM để tổng hợp các hướng dẫn khắc phục, Amazon Q vẫn áp dụng xử lý hậu kỳ (post-processing) để chỉnh sửa các lỗi thường gặp. Ví dụ, trong Ví dụ 2 ở trên, mô hình LLM có thể trả về ARN ở dạng\narn:aws:s3:::\u0026lt;bucket_name\u0026gt; và hệ thống sẽ tự động chỉnh lại chính xác như đã hiển thị ở trên.\nCác hướng dẫn được trả về cho Ví dụ 2 giả định rằng lý do người dùng không thể liệt kê các object là do thiếu câu lệnh Allow trong các policy gắn với role ReadOnly. Tuy nhiên, các nguyên nhân gốc khác có thể là câu lệnh Deny trong một policy được gắn với S3 bucket hoặc với role ReadOnly. Diagnose with Amazon Q có thể sử dụng quá trình truy vấn tài khoản để xác định nguyên nhân gốc chính xác và đề xuất giải pháp phù hợp.\nTrong ví dụ trên, Amazon Q có thể lấy các policy gắn với role ReadOnly để kiểm tra xem quyền s3:ListBucket có thực sự bị thiếu hay không, hoặc lấy các policy gắn với bucket bucket-123456.\nXác thực Một trong những mục tiêu của Diagnose with Amazon Q là duy trì tiêu chuẩn chất lượng cao, đảm bảo người dùng luôn nhận được các gợi ý hữu ích và có thể hành động được bất cứ khi nào gặp lỗi. Điều kiện tiên quyết quan trọng là phải có một hệ thống đánh giá mạnh mẽ và linh hoạt. Việc đánh giá các hệ thống dựa trên Generative AI là một thách thức do không gian đầu ra rất lớn (ngôn ngữ tự nhiên) và tính phi xác định trong phản hồi.\nTóm lại, hệ thống xác thực của chúng tôi được xây dựng dựa trên một bộ dữ liệu lớn về các lỗi, trong đó mỗi bản ghi có một số lượng chú thích nhất định. Mỗi bản ghi chứa ngữ cảnh (thông báo lỗi theo mẫu và URL của Console; nghĩa là bucket-123456 được thay bằng {{s3_bucket_name}}, us-west-2 được thay bằng {{aws_region}}). Các chú thích bao gồm mô tả Infrastructure as Code (CloudFormation) về trạng thái tài khoản có lỗi và hành động kích hoạt lỗi, cũng như các phản hồi đúng được cung cấp bởi các chuyên gia chú thích.\nNhững bản ghi này cho phép chúng tôi mô phỏng hành vi của các biến thể hệ thống mà không cần sự tương tác của con người, và thực hiện nhanh hơn thời gian thực nhiều lần (bằng cách song song hóa). Chúng tôi cũng đang phát triển các chỉ số đánh giá tự động để so sánh giữa chú thích chuẩn và phản hồi của hệ thống, dựa trên đó các bài đánh giá ngoại tuyến có thể được thực hiện một cách hoàn toàn tự động.\nHệ thống xác thực này cho phép chúng tôi nhanh chóng kiểm thử các ý tưởng mới bằng cách so sánh với trạng thái hiện tại, đồng thời ngăn chặn việc thoái lui chất lượng. Mặc dù các chuyên gia con người vẫn cần thiết để tạo chú thích cho các bản ghi lỗi, chúng tôi liên tục đổi mới nhằm tăng tốc và đơn giản hóa các tác vụ này bằng cách phát triển các công cụ chú thích này được thiết kế để tránh việc nhập liệu bằng ngôn ngữ tự nhiên, tích hợp sẵn cơ chế kiểm tra hợp lệ, và yêu cầu chỉnh sửa đầu ra của hệ thống khi cần thiết hơn là cung cấp chú thích thực tế từ đầu.\nKết luận Tính năng Diagnose with Amazon Q của Amazon Q Developer cho phép bạn xác định nguyên nhân của lỗi trong AWS Console mà không cần phải điều hướng qua nhiều bảng điều khiển dịch vụ khác nhau. Bằng cách cung cấp các hướng dẫn chi tiết, từng bước, được tùy chỉnh theo tài khoản AWS và ngữ cảnh lỗi cụ thể, Amazon Q Developer giúp bạn xử lý và khắc phục sự cố một cách hiệu quả.\nĐiều này giúp tổ chức của bạn nâng cao hiệu quả vận hành, giảm thời gian ngừng hoạt động, cải thiện chất lượng dịch vụ, và giải phóng nguồn nhân lực quý giá để họ có thể tập trung vào các hoạt động mang lại giá trị cao hơn.\nChúng tôi cũng cung cấp thông tin chi tiết về cách AI và machine learning hoạt động phía sau để kích hoạt tính năng này.\nVề các tác giả Matthias Seeger\nMatthias Seeger là Principal Applied Scientist tại AWS. Ông quan tâm đến học Bayes và ra quyết định dựa trên mô hình xác suất, lý thuyết và ứng dụng của mô hình Gaussian Process, dự báo xác suất, và gần đây nhất là các mô hình ngôn ngữ lớn (LLM) cùng những thách thức trong việc tạo và gán nhãn dữ liệu liên quan.\nMarco Frattallone\nMarco Frattallone là Senior Technical Account Manager tại AWS, tập trung vào hỗ trợ các đối tác. Ông làm việc chặt chẽ với họ để xây dựng, triển khai và tối ưu hóa giải pháp trên AWS, đồng thời đưa ra hướng dẫn và chia sẻ các phương pháp tốt nhất. Marco đam mê công nghệ và luôn giúp các đối tác dẫn đầu trong đổi mới sáng tạo. Ngoài công việc, ông yêu thích đạp xe, chèo thuyền buồm và khám phá các nền văn hóa mới.\nSurabhi Tandon\nSurabhi Tandon là Senior Technical Account Manager tại Amazon Web Services (AWS). Cô hỗ trợ khách hàng doanh nghiệp đạt được hiệu quả vận hành cao và giúp đỡ họ trong hành trình cloud trên AWS bằng cách cung cấp hướng dẫn kỹ thuật chiến lược. Surabhi có niềm đam mê với Generative AI, tự động hóa, và DevOps. Ngoài công việc, cô thích leo núi, đọc sách và dành thời gian bên gia đình và bạn bè.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Blog Cơ sở dữ liệu AWS Bắt đầu với Apache OFBiz và Amazon Aurora DSQL Tác giả: James Morle | Ngày: 26 tháng 3 năm 2025 | Chuyên mục: Advanced (300), Amazon Aurora, Best Practices, DSQL, Technical How-to\nKhi thiết kế Amazon Aurora DSQL, chúng tôi đã dành rất nhiều thời gian để tìm ra sự cân bằng phù hợp giữa đổi mới và cải tiến so với tính dễ sử dụng. Chúng tôi không muốn làm thay đổi những gì quen thuộc đối với người dùng PostgreSQL hiện tại trừ khi có lý do thực sự thuyết phục. Hai lĩnh vực thuộc nhóm này là hành vi kiểm soát đồng thời lạc quan (Optimistic Concurrency Control – OCC) và mô hình xác thực (authentication model), nơi mà hành vi của hệ thống có thể khiến các nhà phát triển ứng dụng quen thuộc với PostgreSQL cảm thấy khác lạ.\nTrong bài viết này, chúng tôi sẽ trình bày một ví dụ thực tế về cách chuyển đổi một ứng dụng hiện có vốn hoạt động trên cơ sở dữ liệu PostgreSQL sang hoạt động với cơ sở dữ liệu Aurora DSQL. Thêm vào đó việc điều chỉnh để thích ứng với các khía cạnh đã đề cập, chúng tôi cũng sẽ xử lý một số vấn đề không tương thích về kiểu dữ liệu và tìm cách khắc phục một vài giới hạn hiện tại còn tồn tại trong Aurora DSQL.\nỨng dụng Để làm cho ví dụ này mang tính đại diện nhất có thể, chúng tôi đã chọn một ứng dụng mã nguồn mở có tính đa dạng chức năng cao và độ phức tạp đáng kể, phản ánh đúng các ứng dụng thực tế. Ứng dụng đó là Apache OFBiz, và mã nguồn có thể được tải xuống từ kho lưu trữ GitHub. Phiên bản được sử dụng trong bằng chứng khái niệm này là 18.12.16.\nỨng dụng OFBiz là một gói ERP và CRM đầy đủ tính năng, và là một ví dụ điển hình cho mục tiêu của chúng tôi ở đây:\nLược đồ phức tạp: 837 bảng, 4161 chỉ mục Công cụ thực thể trừu tượng hóa (Java Persistence, Java Transactions, custom ORM) Đã hỗ trợ PostgreSQL Dữ liệu demo và chức năng nạp dữ liệu tích hợp sẵn Phần lớn dựa trên mô hình quan hệ, phù hợp với trọng tâm tương thích ban đầu của Aurora DSQL Mục đích của bài viết này là kết hợp phần mô tả quá trình thử nghiệm nội bộ với một số ví dụ mã cụ thể về cách tiếp cận xác thực Aurora DSQL trong ứng dụng connection pool-based Java. Mặc dù chúng tôi cung cấp nhiều ngữ cảnh nhất có thể, nhưng không nhằm mục đích cung cấp một tập lệnh và mã đầy đủ để tái tạo toàn bộ quá trình này.\nAurora DSQL Aurora DSQL là một cơ sở dữ liệu tương thích với PostgreSQL, nhưng có một vài khác biệt về mặt ngữ nghĩa nhằm cải thiện khả năng mở rộng và bảo mật của dịch vụ so với PostgreSQL cộng đồng. Một số khía cạnh trong đó, đặc biệt là mức độ tương thích chức năng rộng với các tính năng PostgreSQL, sẽ phát triển nhanh chóng theo thời gian, nhưng một số ít yếu tố là cốt lõi của hệ thống. Đây là trọng tâm của các thay đổi được thực hiện trong ứng dụng OFBiz và được trình bày trong bài viết này. Những khía cạnh đó bao gồm:\nMô hình xác thực Aurora DSQL – Cách kết nối và duy trì kết nối với cơ sở dữ liệu. Giới hạn kích thước giao dịch – Aurora DSQL không hỗ trợ các giao dịch có kích thước không giới hạn. Mức độ cô lập (Isolation level) – Aurora DSQL chỉ hỗ trợ snapshot isolation, tương đương với repeatable read trong PostgreSQL. Kiểm soát đồng thời lạc quan (Optimistic concurrency control) – Aurora DSQL không khóa tài nguyên trong giai đoạn xây dựng giao dịch; nó đảm bảo tính nhất quán khi commit. Điều này có nghĩa là một số commit có thể thất bại và phải được thực hiện lại từ đầu. Giới hạn kiểu dữ liệu trong khóa – Hiện tại, có một số giới hạn về kiểu dữ liệu (và kích thước) được hỗ trợ trong khóa chính và khóa phụ. Các giới hạn này sẽ giảm dần theo thời gian khi Aurora DSQL bổ sung thêm các kiểu dữ liệu mới. Các biện pháp khắc phục được trình bày trong bài viết này phản ánh các giới hạn tồn tại trong giai đoạn Preview của Aurora DSQL. Tạo cấu hình nguồn dữ liệu cho Aurora DSQL Điều đầu tiên chúng tôi cần làm là định nghĩa một cấu hình nguồn dữ liệu (data source) mới cho cơ sở dữ liệu Aurora DSQL. Chúng tôi đã thêm một nguồn dữ liệu mới có tên là localdsql trong tệp framework/entity/config/entityengine.xml và chọn nó làm nguồn dữ liệu đang hoạt động (active data source). Các tham số của nguồn dữ liệu được sao chép từ nguồn dữ liệu hiện có localpostgres, với các thiết lập được gạch dưới thay đổi như sau:\n\u0026lt;group-map group-name=\u0026#34;org.apache.ofbiz\u0026#34; datasource-name=\u0026#34;localdsql\u0026#34;/\u0026gt; ... \u0026lt;/datasource\u0026gt; \u0026lt;datasource name=\u0026#34;localdsql\u0026#34; helper-class=\u0026#34;org.apache.ofbiz.entity.datasource.GenericHelperDAO\u0026#34; schema-name=\u0026#34;ofbiz\u0026#34; field-type-name=\u0026#34;postgres\u0026#34; check-on-start=\u0026#34;true\u0026#34; add-missing-on-start=\u0026#34;true\u0026#34; use-fk-initially-deferred=\u0026#34;false\u0026#34; alias-view-columns=\u0026#34;false\u0026#34; join-style=\u0026#34;ansi\u0026#34; use-binary-type-for-blob=\u0026#34;true\u0026#34; use-order-by-nulls=\u0026#34;true\u0026#34; result-fetch-size=\u0026#34;50\u0026#34;\u0026gt; \u0026lt;read-data reader-name=\u0026#34;tenant\u0026#34;/\u0026gt; \u0026lt;read-data reader-name=\u0026#34;seed\u0026#34;/\u0026gt; \u0026lt;read-data reader-name=\u0026#34;seed-initial\u0026#34;/\u0026gt; \u0026lt;group-map group-name=\u0026#34;org.apache.ofbiz\u0026#34; datasource-name=\u0026#34;localdsql\u0026#34;/\u0026gt; ... \u0026lt;/datasource\u0026gt; \u0026lt;datasource name=\u0026#34;localdsql\u0026#34; helper-class=\u0026#34;org.apache.ofbiz.entity.datasource.GenericHelperDAO\u0026#34; schema-name=\u0026#34;ofbiz\u0026#34; field-type-name=\u0026#34;postgres\u0026#34; check-on-start=\u0026#34;true\u0026#34; add-missing-on-start=\u0026#34;true\u0026#34; use-fk-initially-deferred=\u0026#34;false\u0026#34; alias-view-columns=\u0026#34;false\u0026#34; join-style=\u0026#34;ansi\u0026#34; use-binary-type-for-blob=\u0026#34;true\u0026#34; use-order-by-nulls=\u0026#34;true\u0026#34; result-fetch-size=\u0026#34;50\u0026#34;\u0026gt; \u0026lt;read-data reader-name=\u0026#34;tenant\u0026#34;/\u0026gt; \u0026lt;read-data reader-name=\u0026#34;seed\u0026#34;/\u0026gt; \u0026lt;read-data reader-name=\u0026#34;seed-initial\u0026#34;/\u0026gt; \u0026lt;/datasource\u0026gt; Trong ví dụ cấu hình ở phần trước, chúng tôi đã ẩn phần endpoint của jdbc-uri— nếu bạn tự thực hiện trên cụm (cluster) của mình, đừng quên cập nhật giá trị để phản ánh đúng endpoint của cụm Aurora DSQL mà bạn đang dùng.\nChúng tôi đặt giá trị jdbc-password thành hằng số đặc biệt IAM_AUTH. OFBiz mặc định giả định rằng chúng ta sẽ sử dụng xác thực bằng mật khẩu thông thường để kết nối cơ sở dữ liệu, nhưng Aurora DSQL yêu cầu cơ chế xác thực dựa trên AWS Identity and Access Management (IAM), nhằm cung cấp một môi trường tích hợp và an toàn hơn. Chúng tôi sẽ thêm hỗ trợ cho cơ chế này trong phần code ở bước tiếp theo.\nChúng tôi cũng thay đổi mức cô lập (isolation level) thành RepeatableRead (đây là hành vi tương đương trong PostgreSQL với mức snapshot isolation của Aurora DSQL) và tăng kích thước nhóm tối thiểu (kết nối trong Aurora DSQL rẻ để duy trì, nhưng kết nối mã hóa thì tương đối chậm để khởi tạo). Aurora DSQL chỉ hỗ trợ kết nối mã hóa, vì vậy chúng tôi đã thêm tham số này vào chuỗi JDBC URI. Chúng tôi cũng triển khai phiên bản mới nhất của driver PG JDBC (42.7.4 tại thời điểm viết) để đảm bảo đây là phiên bản được chứng nhận tương thích với Aurora DSQL.\nTriển khai logic kết nối cho Aurora DSQL Có ba yếu tố cần xem xét khi xây dựng logic kết nối cho Aurora DSQL:\n• Mật khẩu thực tế là token xác thực động, được tạo theo yêu cầu khi cơ chế xác thực IAM được xác minh.\n• Token xác thực có thời hạn — chúng chỉ hợp lệ trong khoảng thời gian được chỉ định khi tạo ra. Thời hạn này có thể lên đến một tuần, phù hợp khi dùng cho các công cụ phát triển, nhưng đối với ứng dụng thực tế, chúng tôi khuyến nghị thời hạn ngắn hơn nhiều để giảm nguy cơ truy cập trái phép. Chúng tôi chọn thời hạn 3 giờ trong trường hợp này.\n• Kết nối cũng có thời hạn, hiện tại mỗi giờ. Sự tương tác giữa token xác thực và thời hạn kết nối có thể gây nhầm lẫn với người dùng mới của Aurora DSQL, nên cần nhớ token xác thực chỉ được áp dụng khi tạo một kết nối (token phải vẫn còn hiệu lực tại thời điểm tạo kết nối) và thời hạn kết nối chỉ ảnh hưởng đến các kết nối hiện có (không phụ thuộc vào thời hạn của token sau khi kết nối được thiết lập).\nĐể hỗ trợ cơ chế này, chúng tôi chỉnh sửa tệp\nframework/entity/src/main/java/org/apache/ofbiz/entity/config/model/EntityConfig.java để thêm luồng xác thực riêng cho Aurora DSQL, bổ sung logic sau:\npublic static String getJdbcPassword(InlineJdbc inlineJdbcElement) throws GenericEntityConfException { String jdbcPassword = inlineJdbcElement.getJdbcPassword(); + if (!jdbcPassword.isEmpty() \u0026amp;\u0026amp; ! jdbcPassword.equals(\u0026#34;IAM_AUTH\u0026#34;)) { return jdbcPassword; } + if (jdbcPassword.equals(\u0026#34;IAM_AUTH\u0026#34;)) { + return DSQLAuth.generateToken(inlineJdbcElement.getJdbcUri().split(\u0026#34;/\u0026#34;)[2], + Region.US_EAST_1, Sau đó, chúng tôi chỉnh sửa tệp framework/entity/src/main/java/org/apache/ofbiz/entity/connection/DBCPConnectionFactory.java để sử dụng ConnectionFactory dành riêng cho Aurora DSQL khi data source là localdsql. Chúng tôi cũng đặt thời gian tồn tại tối đa của kết nối (maximum connection lifetime) trong nhóm ngắn hơn một chút so với thời gian kết nối tối đa được hỗ trợ trong Aurora DSQL.\n// create the connection factory + org.apache.commons.dbcp2.ConnectionFactory cf = null; + if (cacheKey.equals(\u0026#34;localdsql\u0026#34;)) { + cf = new DSQLConnectionFactory(jdbcDriver, jdbcUri, cfProps); + } else { + cf = new DriverConnectionFactory(jdbcDriver, jdbcUri, cfProps); + } // wrap it with a LocalXAConnectionFactory XAConnectionFactory xacf = new LocalXAConnectionFactory(txMgr, cf); // create the pool object factory PoolableConnectionFactory factory = new PoolableManagedConnectionFactory(xacf, null); + ((PoolableManagedConnectionFactory)factory).setMaxConnLifetimeMillis((long)55*60*1000); factory.setValidationQuery(jdbcElement.getPoolJdbcTestStmt()); Cuối cùng, chúng tôi thêm phần logic cốt lõi để quản lý các kết nối, bao gồm việc thêm Aurora DSQL SessionId vào thuộc tính của kết nối nhằm hỗ trợ việc chẩn đoán tốt hơn. Khi cần liên hệ với AWS Support để xử lý các vấn đề liên quan đến Aurora DSQL, việc cung cấp Session ID của kết nối cụ thể gặp sự cố sẽ rất hữu ích. Chúng tôi đã triển khai các lớp cụ thể (concrete classes) sau đây:\nframework/entity/src/main/java/org/apache/ofbiz/entity/connection/Aurora DSQLAuth.java framework/entity/src/main/java/org/apache/ofbiz/entity/connection/Aurora DSQLConnectionFactory.java framework/entity/src/main/java/org/apache/ofbiz/entity/connection/Aurora DSQLConnection.java Chỉnh sửa lược đồ Chúng tôi thực hiện các thay đổi tối thiểu đối với lược đồ cơ sở dữ liệu để tuân thủ các giới hạn hiện đang áp dụng cho Aurora DSQL. Phần lớn lược đồ ban đầu đã tương thích với Aurora DSQL, nhưng chúng tôi có thể thực hiện nhiều điều chỉnh hơn nếu không cần giữ lại dữ liệu demo hiện có (vấn đề này sẽ được nói rõ hơn ở các phần sau). Các giới hạn cần khắc phục đều liên quan đến kiểu dữ liệu được hỗ trợ trong khóa (key) của Aurora DSQL:\nKiểu NUMERIC hiện chưa được hỗ trợ trong khóa: Chúng tôi chỉnh sửa applications/datamodel/entitydef/product-entitymodel.xml, đổi kiểu dữ liệu của minimumOrderQuantity sang floating-point (float) thay vì fixed-point (NUMERIC(18,6)). Nói chung, hai kiểu này không hoàn toàn tương đương về mặt logic, nhưng dữ liệu demo lại dùng kiểu dữ liệu thập phân. Một thay đổi tốt hơn ở đây sẽ là thay đổi dữ liệu demo, nhưng trong trường hợp này, logic vẫn hoạt động đúng (vì chỉ dùng phép so sánh “lớn hơn”). Chúng tôi chỉnh sửa framework/entity/fieldtype/fieldtypepostgres.xml để thay đổi định nghĩa của thành . Việc dùng bigint ở đây thực tế phù hợp hơn so với NUMERIC(20,0). Kiểu VARCHAR được hỗ trợ trong keys, nhưng kích thước tối đa nhỏ hơn so với VARCHAR thông thường: Chúng tôi chỉnh sửa framework/entity/fieldtype/fieldtypepostgres.xml, để đổi định nghĩa của thành . Sau khi thực hiện các thay đổi này, lược đồ (schema) đã có thể được tạo thành công trong quá trình tải dữ liệu (xem chi tiết ở phần tiếp theo). Chúng tôi sử dụng tùy chọn -l drop-constraints trong tiện ích OFBiz loader để đảm bảo rằng không có bảng nào được tạo bằng cách sử dụng ràng buộc khóa ngoại (foreign key constraints), những foreign key constraints này hiện tại chưa được hỗ trợ trong Aurora DSQL.\nNhư đã đề cập trước đó, chúng tôi có thể tối ưu hóa lược đồ sâu hơn. Một thay đổi đáng chú ý mà chúng tôi không cần thực hiện là chuyển kiểu dữ liệu của các trường ID sang UUID, điều vốn phổ biến trong ứng dụng sử dụng ORM. Bởi vì chúng tôi đang sử dụng dữ liệu demo, chúng tôi sẽ cần phải sửa đổi tất cả các khóa (và tham chiếu) trong dữ liệu demo để áp dụng các kiểu UUID. Thay vào đó, chúng tôi giữ nguyên kiểu khóa dựa trên VARCHAR và tải dữ liệu demo mà không cần thay đổi.\nTải dữ liệu demo OFBiz data loader (xem OFBiz Technical Setup Guide) ban đầu thực hiện một số lượng lớn thao tác chèn trước mỗi lần commit, khiến một số giao dịch vượt quá giới hạn kích thước transaction trong Aurora DSQL trong một số trường hợp. Để khắc phục vấn đề này, chúng tôi chỉnh sửa phương thức storeAll() trong file framework/entity/src/main/java/org/apache/ofbiz/entity/GenericDelegator.java để chia quá trình tải dữ liệu hàng loạt thành các lô có thể tải dữ liệu 1.000 dòng mỗi lần.\nnumberChanged += this.store(toStore); } } + // commit every 1000 rows to conform to DSQL transaction limits + if (numberChanged%1000 == 0) { + if (Debug.verboseOn()) Debug.logVerbose(\u0026#34;Committing at 1000 row threshold. beganTransaction=\u0026#34; + beganTransaction, module); + TransactionUtil.commit(); + beganTransaction = TransactionUtil.begin(); + } } TransactionUtil.commit(beganTransaction); return numberChanged; Lưu ý: Giới hạn kích thước transaction trong Aurora DSQL thực tế lớn hơn 1.000 dòng, nhưng chúng tôi chọn giá trị nhỏ hơn này để dễ dàng quan sát hành vi batching (xử lý theo lô) sau khi thay đổi logic. Chúng tôi cũng sửa một lỗi khác khá thú vị trong quá trình dò tìm. Một phần của logic tải dữ liệu gọi đến hàm findKey() trong file framework/entity/src/main/java/org/apache/ofbiz/entity/util/EntityCrypto.java để kiểm tra sự tồn tại của khóa mã hóa (crypto key) trong cơ sở dữ liệu. Nếu khóa này không tồn tại ở vị trí mong đợi, quá trình tải dữ liệu sẽ dừng lại và báo lỗi. Khi thử nghiệm với Aurora DSQL, điều kiện bất biến này luôn bị kích hoạt. Sau khi tìm hiểu kỹ, chúng tôi phát hiện có một lỗi logic tổng quát, dẫn đến sự khác biệt trong hành vi giữa hai mức cô lập giao dịch read committed và repeatable read. Phương thức findKey() được gọi mà không bắt đầu một transaction mới, nên nó chỉ nhìn thấy dữ liệu tại thời điểm snapshot của transaction hiện tại. Vì snapshot đó xảy ra trước khi lệnh INSERT tương ứng được commit, nên findKey() không thể thấy dòng dữ liệu vừa được chèn. Trong mức cô lập read committed, lời gọi findKey() hoạt động bình thường vì session có thể thấy dữ liệu đã commit kể từ khi transaction bắt đầu. Để khắc phục, chúng tôi bắt đầu một transaction mới mỗi khi hàm findKey() được gọi:\nGenericValue keyValue = null; try { + try { + keyValue = TransactionUtil.doNewTransaction(() -\u0026gt; { + return EntityQuery.use(delegator).from(\u0026#34;EntityKeyStore\u0026#34;).where(\u0026#34;keyName\u0026#34;, hashedKeyName).queryOne(); + }, \u0026#34;checking encrypted key\u0026#34;, 0, true); + } catch (GenericEntityException e) { + throw new EntityCryptoException(e); + } } catch (GenericEntityException e) { throw new EntityCryptoException(e); } Chúng tôi đã tải dữ liệu khởi tạo (seed) và dữ liệu minh họa (demo) theo hướng dẫn trong tài liệu thiết lập kỹ thuật của OFBiz (OFBiz Technical Setup Guide). Xử lý OCC aborts trong transaction command pattern Ứng dụng OFBiz gửi các giao dịch (transactions) đến cơ sở dữ liệu bằng mẫu lệnh (command pattern) — sử dụng giao diện Callable — giúp việc xử lý các giao dịch của Aurora DSQL trở nên đơn giản hơn. Các ứng dụng khác (ngoài OFBiz) nếu cũng đóng gói toàn bộ giao dịch theo cách này thì việc quản lý cũng tương tự, vì ranh giới của từng giao dịch đều được xác định rõ ràng. Tất cả những gì cần thực hiện ở đây, ít nhất là cho mục đích minh họa, là thêm một vòng lặp retry quanh phần thực thi giao dịch. Vòng lặp này được đặt trong tệp: framework/entity/src/main/java/org/apache/ofbiz/entity/transaction/TransactionUtil.java trong phương thức InTransaction.call().\nprotected InTransaction(Callable\u0026lt;V\u0026gt; callable, String ifErrorMessage, int timeout, boolean printException) { this.callable = callable; this.ifErrorMessage = ifErrorMessage; this.timeout = timeout; this.printException = printException; } public V call() throws GenericEntityException { + boolean transactionComplete = false; + while (!transactionComplete) { boolean tx = TransactionUtil.begin(timeout); Throwable transactionAbortCause = null; try { try { return callable.call(); } catch (Throwable t) { while (t.getCause() != null) { t = t.getCause(); } throw t; } } catch (Error | RuntimeException e) { transactionAbortCause = e; throw e; } catch (Throwable t) { transactionAbortCause = t; + if (t instanceof SQLException \u0026amp;\u0026amp; (((SQLException) t).getSQLState().startsWith(\u0026#34;OC\u0026#34;) + || ((SQLException) t).getSQLState().equals(\u0026#34;40001\u0026#34;))) { + if (Debug.verboseOn()) { + Debug.logVerbose(\u0026#34;Transaction abort, reason: \u0026#34; + t, module); + Debug.logVerbose(\u0026#34;Retrying on OCC conflict\u0026#34;, module); + } + // Rollback to recover transaction state and loop again + TransactionUtil.rollback(tx, ifErrorMessage, transactionAbortCause); + continue; + } else { throw new GenericEntityException(t); + } } finally { if (transactionAbortCause == null) { TransactionUtil.commit(tx); + transactionComplete = true; } else { if (printException) { Debug.logError(transactionAbortCause, module); } TransactionUtil.rollback(tx, ifErrorMessage, transactionAbortCause); + transactionComplete = true; + } } } + throw new GenericEntityException(\u0026#34;Unexpected state in transaction handler\u0026#34;); } } Lưu ý: Đối với các ứng dụng sản xuất, chúng tôi cũng khuyên bạn nên bổ sung thêm logic cho exponential backoff và jitter, điều này giúp hệ thống hoạt động ổn định hơn trong điều kiện xung đột cao. Các ứng dụng hiện có không mô hình hóa giao dịch rõ ràng theo cách này có thể cần được phân tích sâu hơn để xác định cách xử lý OCC aborts một cách chính xác. Chúng tôi dự định sẽ viết một bài đăng trong tương lai về chủ đề này, sau khi có thêm dữ liệu từ trải nghiệm thực tế của khách hàng để xác định các mô hình phổ biến nhất.\nKết luận Trong bài viết này, chúng tôi đã hướng dẫn bạn qua các thay đổi khác nhau được thực hiện đối với một ứng dụng phức tạp hiện có. Chúng tôi đã thực hiện một số sửa đổi nhỏ đối với schema để sử dụng các kiểu dữ liệu được hỗ trợ, tạo logic mới để tương tác đúng với cơ chế xác thực của Aurora DSQL, triển khai việc gom commit khi tải dữ liệu, và làm cho bộ xử lý giao dịch hoạt động đúng với ngữ nghĩa OCC. Mặc dù bản proof of concept này tập trung vào tính khả thi kỹ thuật hơn là mức độ sẵn sàng cho môi trường production, nó đã chứng minh rằng Aurora DSQL có thể hỗ trợ các ứng dụng cơ sở dữ liệu phức tạp như OFBiz với nỗ lực di chuyển hợp lý. Thử nghiệm này xác nhận rằng ngay cả những ứng dụng có schema phức tạp vẫn có thể được điều chỉnh để hoạt động với Aurora DSQL, bao gồm các tính năng bảo mật và khả năng mở rộng được cải thiện, thông qua các điều chỉnh có mục tiêu đối với xác thực, xử lý giao dịch và thiết kế schema. Những khía cạnh này cũng là các trọng tâm chính khi bạn lên kế hoạch migrations của riêng mình sang Aurora DSQL:\nSử dụng các kiểu dữ liệu được hỗ trợ trong schema, bao gồm cả keys Triển khai logic xác thực dựa trên IAM cần thiết cho Aurora DSQL Đảm bảo kích thước giao dịch nằm trong giới hạn của Aurora DSQL Triển khai các giao dịch idempotent và có thể retry được Nếu bạn đang làm việc với các ứng dụng hiện có sử dụng Aurora DSQL, chúng tôi mời bạn chia sẻ kinh nghiệm và quan sát của mình trong phần bình luận! Về tác giả\nJames Morle là Principal Engineer tại Amazon Web Services và đã tham gia sâu vào quá trình thiết kế và triển khai Aurora DSQL ngay từ những ngày đầu tiên. Ông đã có kinh nghiệm thiết kế và xây dựng các cơ sở dữ liệu quy mô rất lớn từ đầu những năm 1990.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 08/09/2025 08/09/2025 3 - Tạo tài khoản AWS Free Tier - Tìm hiểu về AWS và các mô hình triển khai 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu cơ sở hạ tầng của AWS trên thế giới và các dịch vụ cốt lõi 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu về EC2 và thực hành + Instance + Instance type + \u0026hellip; 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025” Event Về Chương trình AWS First Cloud Journey Workforce ​- Khởi động từ năm 2021, chương trình đã đồng hành cùng hơn 2,000 sinh viên trên khắp cả nước.\n​Hơn 150 học viên đã được đào tạo chuyên sâu và hiện đang làm việc tại các công ty công nghệ hàng đầu Việt Nam và quốc tế. ​Mục tiêu chính: ​Xây dựng thế hệ AWS Builders chất lượng cao cho Việt Nam. ​- Trang bị kỹ năng thực chiến về Cloud, DevOps, AI/ML, Security, Data \u0026amp; Analytics. ​Kết nối sinh viên với cộng đồng AWS Study Group 47,000+ thành viên và các doanh nghiệp đối tác AWS. ​Chương trình không chỉ là đào tạo công nghệ, mà còn là cầu nối quan trọng giữa tri thức – công nghệ – sự nghiệp, giúp sinh viên tự tin hòa nhập vào thế giới công nghệ hiện đại và hội nhập quốc tế. Tên sự kiện: Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025\nThời gian: 08:30 ngày 06/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nDiễn giả và khách mời ​Đại diện Nhà trường: Thầy Nguyễn Trần Phước Bảo – Trưởng phòng Quan hệ Doanh nghiệp (QHDN) phát biểu khai mạc ​Tham dự cùng 2–3 anh/chị thuộc Phòng QHDN ​Keynote \u0026amp; Industry Sharing AWS First Cloud Journey \u0026amp; Định hướng Tương lai 👤 Nguyễn Gia Hưng – Head of Solutions Architect, AWS Vietnam\nDevOps \u0026amp; Sự nghiệp tương lai 👤 Đỗ Huy Thắng – DevOps Lead, VNG\n​Alumni \u0026amp; Career Sharing Từ First Cloud Journey đến GenAI Engineer 👤 Danh Hoàng Hiếu Nghị – GenAI Engineer, Renova\nShe in Tech \u0026amp; Hành trình cùng First Cloud Journey 👤 Bùi Hồ Linh Nhi – AI Engineer, SoftwareOne\nMột ngày làm Cloud Engineer 👤 Phạm Nguyễn Hải Anh – Cloud Engineer, G-Asia Pacific\nHành trình đến với First Cloud Journey 👤 Nguyễn Đồng Thanh Hiệp – Principal Cloud Engineer, G-Asia Pacific\n​✨ Lời kết ​Sự kiện Kick-off hôm nay chính là bước khởi đầu cho hành trình AWS Builders – nơi các bạn sinh viên không chỉ tiếp cận công nghệ điện toán đám mây tiên tiến nhất, mà còn được truyền cảm hứng, kết nối cùng chuyên gia và mở rộng cơ hội nghề nghiệp.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Tại phần này, bạn cần tóm tắt các nội dung trong workshop mà bạn dự tính sẽ làm.\nStudying English Website 1. Tóm tắt điều hành Studying English Website được thiết kế dành cho các bạn học tiếng anh nhằm nâng cao khả năng học từ vựng, ngữ pháp và giao tiếp hằng ngày. Nền tảng tận dụng các dịch vụ AWS Serverless để cung cấp giám sát thời gian học tập, phân tích dự đoán khả năng học người học để đưa ra những chính sách học tập theo trình từ cơ bản đến nâng cao và tiết kiệm chi phí ở mức thấp nhất.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nTiếng anh là ngoại ngữ thiết yếu cho công việc và đời sống. Tuy nhiên, người học đang không có không gian và môi trường luyện tập, đặc biệt là trong việc giao tiếp.\nGiải pháp Để giải quyết vấn đề thiếu môi trường luyện tập tiếng Anh và hỗ trợ người học nâng cao kỹ năng từ vựng, ngữ pháp và giao tiếp, chúng tôi đề xuất xây dựng Studying English Website trên nền tảng serverless của AWS, cho phép học tập cá nhân hóa dựa trên dữ liệu người dùng, tích hợp bài tập nghe – nói và video hướng dẫn với ghi âm người học lưu trữ trên S3, theo dõi và phân tích tiến trình học bằng AWS Lambda , đảm bảo bảo mật và quản lý người dùng qua Cognito đồng thời triển khai giao diện web nhanh chóng, tiết kiệm chi phí bằng AWS Amplify, mang đến môi trường học linh hoạt, an toàn và hiệu quả, đồng thời giúp nhà quản lý cải thiện phương pháp học dựa trên dữ liệu thực tế.\nLợi ích và hoàn vốn đầu tư (ROI) Nền tảng Studying English Website giúp người học nâng cao kỹ năng tiếng Anh một cách cá nhân hóa và linh hoạt, giảm thời gian và chi phí so với phương pháp học truyền thống, đồng thời cung cấp dữ liệu phân tích tiến trình học cho nhà quản lý để tối ưu phương pháp giảng dạy; với chi phí hạ tầng AWS thấp (~6,45 USD/tháng), dự án có khả năng hoàn vốn nhanh thông qua việc tăng hiệu quả học tập và mở rộng số lượng người dùng, đồng thời tạo nền tảng dữ liệu giá trị cho các dự án AI và phân tích lâu dài.\n3. Kiến trúc giải pháp Kiến trúc giải pháp của Studying English Website dựa trên nền tảng serverless của AWS, sử dụng S3 để lưu trữ dữ liệu thô và dữ liệu đã xử lý, Amplify Gen 2 để triển khai giao diện web Route53 quản lý DNS và định tuyến, Cognito xác thực và quản lý người dùng, Secrets Manager bảo mật thông tin nhạy cảm, IAM quản lý quyền truy cập, Lambda xử lý logic serverless theo sự kiện, WAF bảo vệ ứng dụng khỏi tấn công tạo ra một hệ thống học tiếng Anh linh hoạt, cá nhân hóa, an toàn và dễ mở rộng.\nDịch vụ AWS sử dụng\nAWS Amplify gen 2: Lưu trữ giao diện web AWS Route53: Quản lý DNS và định tuyến. AWS Cognitor: Xác thực và quản lý người dùng. AWS IAM: Quản lý quyền truy cập AWS. AWS Lambda: Chạy code serverless theo sự kiện. AWS WAF: Bảo vệ ứng dụng web khỏi tấn công. AWS SES: Gửi xác nhận người dùng qua Email. Thiết kế thành phần\nTiếp nhận dữ liệu: Dữ liệu từ người dùng và các nguồn được gửi tới AWS Lambda, Lambda nhận và kích hoạt các quy trình xử lý. Lưu trữ dữ liệu: Dữ liệu thô và dữ liệu đã xử lý được lưu trữ trên AWS S3 với nhiều bucket riêng biệt, tạo data lake và kho dữ liệu sẵn sàng phân tích. Xử lý dữ liệu: AWS Lambda xử lý các sự kiện serverless, MediaConvert chuyển đổi video/audio, dữ liệu được lập chỉ mục. Giao diện web: AWS Amplify Gen 2 lưu trữ ứng dụng Next.js cung cấp bảng điều khiển, phân tích thời gian thực và truy cập dữ liệu người dùng. *Quản lý người dùng8: Amazon Cognito xác thực và quản lý quyền truy cập người dùng, kết hợp AWS IAM kiểm soát quyền truy cập dịch vụ AWS, bảo vệ thông tin nhạy cảm qua AWS Secrets Manager và bảo vệ toàn bộ ứng dụng bằng AWS WAF; DNS và định tuyến được quản lý bởi Route53. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần — xây dựng nền tảng Studying English Website — mỗi phần trải qua 4 giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu và thiết kế kiến trúc AWS Serverless (1 tháng trước kỳ thực tập). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính chi phí hạ tầng và điều chỉnh dịch vụ, đảm bảo dự án vừa khả thi vừa tiết kiệm (Tháng 1). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh các dịch vụ (ví dụ tối ưu Lambda, MediaConvert, Amplify) và quy trình xử lý dữ liệu để đạt hiệu quả tối đa (Tháng 2). Phát triển, kiểm thử, triển khai: triển khai các dịch vụ AWS bằng CDK/SDK, phát triển giao diện Next.js trên Amplify, kiểm thử toàn bộ hệ thống và đưa vào vận hành (Tháng 2–3). Yêu cầu kỹ thuật\nHệ thống yêu cầu kết nối internet ổn định để vận hành các dịch vụ AWS, bao gồm lưu trữ và truy xuất dữ liệu trên S3, xử lý dữ liệu serverless bằng Lambda, triển khai giao diện web Next.js trên Amplify Gen 2, quản lý DNS và định tuyến bằng Route53, xác thực và quản lý quyền truy cập người dùng với Cognito, bảo mật thông tin nhạy cảm qua Secrets Manager, kiểm soát quyền truy cập dịch vụ AWS bằng IAM và bảo vệ ứng dụng bằng WAF, đồng thời hỗ trợ phân tích dữ liệu và bảng điều khiển thời gian thực. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): lên kế hoạch học tập Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Học cách triển khai, lên kế hoạch và vẽ kiến trúc Tháng 3: Triển khai, kiểm thử và đưa vào sử dụng Sau triển khai: Nghiên cứu tiềm năng phát triển và chức năng mới cho chương trình Ước tính ngân sách 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS S3: 0,15 USD/tháng (6 GB, 2 bucket, 2.100 request) AWS Amplify gen 2: 0,35 USD/tháng (256 MB, request 500 ms) AWS Route53: 0,50 USD/tháng (1 domain, 1 triệu query) AWS Cognito: 0,00 USD/tháng (5 người dùng Free tier) AWS IAM: 0 USD/tháng AWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB RAM) AWS WAF: 5,00 USD/tháng (1 Web ACL cơ bản) Tổng: 5.85 USD/tháng, ~70.2 USD/12 tháng\n7. Đánh giá rủi ro Ma trận rủi ro\nSập server: Ảnh hưởng cao, xác xuất trung bình Vượt ngân sách: Ảnh hưởng trung bình, xác suất cao Chiến lược giảm thiểu\nChỉ phí: sử dụng AWS Budget để cảnh báo, tối ưu dịch vụ Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu và làm project nhóm 03/11/2025 07/11/2025 3 - Nghiên cứu và làm project nhóm 03/11/2025 07/11/2025 4 - Nghiên cứu và làm project nhóm 03/11/2025 07/11/2025 5 - Nghiên cứu và làm project nhóm 03/11/2025 07/11/2025 6 - Nghiên cứu và làm project nhóm 03/11/2025 07/11/2025 Kết quả đạt được tuần 10: Đang có tiến triển tốt trong Nghiên cứu và làm project nhóm "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu và làm project nhóm 10/11/2025 14/11/2025 3 - Nghiên cứu và làm project nhóm 10/11/2025 14/11/2025 4 - Nghiên cứu và làm project nhóm 10/11/2025 14/11/2025 5 - Nghiên cứu và làm project nhóm 10/11/2025 14/11/2025 6 - Nghiên cứu và làm project nhóm 10/11/2025 14/11/2025 Kết quả đạt được tuần 11: Đang có tiến triển tốt trong Nghiên cứu và làm project nhóm "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tham gia sự kiện AWS Cloud Mastery Series #2 17/11/2025 17/11/2025 3 - Tiếp tục nghiên cứu và làm project nhóm 18/11/2025 21/11/2025 4 - Tiếp tục nghiên cứu và làm project nhóm 18/11/2025 21/11/2025 5 - Tiếp tục nghiên cứu và làm project nhóm 18/11/2025 21/11/2025 6 - Tiếp tục nghiên cứu và làm project nhóm 18/11/2025 21/11/2025 Kết quả đạt được tuần 12: Đang có tiến triển tốt trong Nghiên cứu và làm project nhóm. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;CognitoPermissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cognito-idp:AdminCreateUser\u0026#34;, \u0026#34;cognito-idp:AdminUpdateUserAttributes\u0026#34;, \u0026#34;cognito-idp:ListUsers\u0026#34;, \u0026#34;cognito-idp:SignUp\u0026#34;, \u0026#34;cognito-idp:InitiateAuth\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;LambdaPermissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:ListFunctions\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:UpdateFunctionCode\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3Permissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::your-bucket-name/*\u0026#34;, \u0026#34;arn:aws:s3:::your-bucket-name\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBPermissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:UpdateItem\u0026#34;, \u0026#34;dynamodb:Query\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:region:account-id:table/your-table-name\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;SESPermissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ses:SendEmail\u0026#34;, \u0026#34;ses:SendRawEmail\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudWatchPermissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudwatch:PutMetricData\u0026#34;, \u0026#34;cloudwatch:GetMetricData\u0026#34;, \u0026#34;cloudwatch:DescribeAlarms\u0026#34;, \u0026#34;cloudwatch:SetAlarmState\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;WAFPermissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;wafv2:CreateWebACL\u0026#34;, \u0026#34;wafv2:UpdateWebACL\u0026#34;, \u0026#34;wafv2:GetWebACL\u0026#34;, \u0026#34;wafv2:ListWebACLs\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;IAMPermissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:ListPolicies\u0026#34;, \u0026#34;iam:GetRole\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Kiến thức nền tảng Workshop giả định người đọc có một số kiến thức cơ bản:\nLập trình web\nHTML, CSS, JavaScript/TypeScript, React hoặc một framework SPA tương tự. Kiến thức nền về Cloud và AWS\nKhái niệm region, account, Hiểu sơ lược về dịch vụ managed (Cognito, Lambda, DynamoDB,…), Khái niệm cơ bản về IAM (identity, role, policy, least privilege). Công cụ và dịch vụ Để có thể tái hiện workshop trong một môi trường thực tế, bạn sẽ cần các công cụ và dịch vụ sau:\nMột tài khoản AWS với quyền tạo:\nAWS Amplify, Cognito User Pools, AWS Lambda, AWS DynamoDB, Các identity và configuration set của SES, CloudWatch, IAM roles và policies. Node.js và npm cài đặt trên máy local\n(để chạy và build frontend React).\nAWS CLI đã được cấu hình với IAM user hoặc role có đủ quyền.\n(Tuỳ chọn) Amplify CLI / Gen 2 tooling\nđể định nghĩa hạ tầng bằng code và kết nối dự án với Amplify.\nMã nguồn và cấu trúc dự án Dự án English Journey được tổ chức như sau:\nMột frontend React (các trang như Level Test, Dictionary, Vocabulary, Quiz, Reading), Backend được định nghĩa thông qua Amplify (Cognito, Lambda, DynamoDB), Hạ tầng bổ sung cho SES (email), CloudWatch và WAF. Các mục tiếp theo (từ 5.3 trở đi) sẽ dựa trên các điều kiện tiên quyết này và giải thích chi tiết hơn từng nhóm dịch vụ AWS.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-create-amplify/",
	"title": "Tạo backend với Amplify",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Phần này mô tả quy trình tạo backend bằng AWS Amplify cho ứng dụng web English Journey.\nThay vì tự tay cấu hình từng dịch vụ như Amazon Cognito, AWS Lambda, Amazon S3, AWS WAF hay Amazon DynamoDB trên console, nhóm sử dụng AWS Amplify (Gen 2) như một lớp nền tảng backend. Amplify đọc cấu hình từ project và sinh ra các resource cần thiết cho xác thực, API, lưu trữ dữ liệu và hosting.\n5.3.1 Vì sao dùng Amplify? English Journey là ứng dụng React single-page. Nhóm chọn Amplify vì:\nCung cấp một điểm trung tâm để cấu hình backend cho web/mobile, Tự động tạo Cognito, Lambda, DynamoDB, S3, CloudFront dựa trên cấu hình đơn giản, Dễ tích hợp với thư viện Amplify cho JavaScript mà frontend đang sử dụng (đăng nhập, gọi API, upload file,…). Nói cách khác, Amplify đóng vai trò “nền tảng backend”, giúp sinh viên không phải thao tác nhiều với từng dịch vụ AWS ở mức thấp.\n5.3.2 Tạo Amplify App và hosting frontend Nhóm tạo một Amplify App mới từ AWS Management Console và kết nối với repository chứa mã nguồn React của English Journey. Trong wizard cấu hình: Bước build (cài dependency và chạy npm run build), Các biến môi trường cần cho ứng dụng. Amplify tự động tạo: Một bucket S3 để lưu các file build của frontend, Một CloudFront distribution đứng trước bucket để phân phối website với độ trễ thấp. Kết quả là có một URL public nơi frontend của English Journey được host. Các tài nguyên backend (Cognito, Lambda, DynamoDB, …) về sau đều gắn với Amplify App này. 5.3.3 Xác thực người dùng với Cognito (Amplify Auth) Để hỗ trợ người học đăng ký, đăng nhập và quên mật khẩu, nhóm sử dụng Auth trong Amplify.\nVề mặt cấu hình:\nKhai báo nhu cầu xác thực trong Amplify: Đăng nhập bằng email + mật khẩu, Cho phép tự đăng ký tài khoản mới, Cấu hình chính sách mật khẩu và email xác nhận. Amplify sinh ra một Amazon Cognito User Pool với cấu hình tương ứng. Frontend React dùng Amplify Auth library để: Đăng ký tài khoản (sign up), Đăng nhập (sign in), Đọc thông tin user (name, email) và hiển thị lời chào “Chào mừng trở lại, tên User!”. Token do Cognito cấp (ID token, access token) được dùng để bảo vệ các API và Lambda phía sau.\n5.3.4 Xử lý nghiệp vụ bằng Lambda (Amplify Functions) Phần nghiệp vụ chính của English Journey chạy trong AWS Lambda.\nNhóm khai báo nhiều function trong Amplify, tiêu biểu như:\nMyLearning / DailyCheckIn – cập nhật chuỗi ngày học và tiến độ học cho từng user. LevelTest – nhận đáp án bài test, tính toán mức CEFR (A1–C1) và lưu kết quả. Dictionary / Vocabulary – cung cấp API tra từ, lưu “từ đã lưu”. Trong cấu hình Amplify, các function này được định nghĩa dưới dạng backend handler. Khi deploy, Amplify tạo từng Lambda function riêng kèm:\nIAM Role phù hợp (quyền truy cập DynamoDB, SES,…), Biến môi trường (tên bảng, ARN của các dịch vụ liên quan). 5.3.5 Tầng dữ liệu với DynamoDB Để lưu dữ liệu của ứng dụng, nhóm định nghĩa các model trong backend và để Amplify map sang bảng Amazon DynamoDB, ví dụ:\nUserProfiles – thông tin cơ bản và tùy chọn học tập của người dùng. PlacementTestResults – điểm và level phát hiện được cho từng lần làm bài test. Vocabulary / Dictionary – danh sách từ vựng, nghĩa tiếng Việt, ví dụ, level CEFR. UserProgress – từ đã lưu, từ đã đánh dấu “mastered”, lịch sử quiz, daily streak. Các Lambda function nhận tên bảng qua biến môi trường do Amplify sinh ra và truy cập DynamoDB bằng AWS SDK.\nViệc mô tả bảng trong code giúp quá trình deploy có thể lặp lại và dễ quản lý phiên bản.\n5.3.6 Bảo vệ lớp frontend với AWS WAF Điểm truy cập public của ứng dụng là CloudFront distribution do Amplify tạo ra.\nĐể bảo vệ endpoint này, nhóm gắn một AWS WAF Web ACL vào CloudFront và bật:\nCác AWS managed rule group chặn tấn công phổ biến (SQL injection, XSS, bot,…), Một rule giới hạn tần suất request cơ bản nhằm giảm nguy cơ bị spam/DoS đơn giản. Trên sơ đồ kiến trúc, phần này được thể hiện bởi khối AWS WAF đứng trước Amplify.\nTóm tắt Trong dự án English Journey, Amplify là dịch vụ trung tâm dùng để:\nTạo và kết nối Cognito (xác thực), Triển khai Lambda (xử lý nghiệp vụ), Quản lý DynamoDB (dữ liệu ứng dụng), Cấu hình S3 + CloudFront (hosting và nội dung tĩnh), Kết hợp với AWS WAF để tăng cường bảo mật. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Tối ưu hóa chi phí điện toán đám mây: Cẩm nang Rehost Migration (Phần 4 – Di trú: Hiện thực hóa kế hoạch tiết kiệm chi phí) Bài blog này là phần 4 trong chuỗi hướng dẫn tối ưu chi phí khi di trú (Rehost Migration) lên AWS, tập trung vào giai đoạn migrate - hiện thực hóa kế hoạch tiết kiệm chi phí đã lập. Bài viết giới thiệu 4 công cụ chính của AWS để tối ưu chi phí sau khi migration: AWS Billing and Cost Management (giám sát và phân tích chi phí tổng thể), AWS Cost Explorer (trực quan hóa xu hướng chi tiêu), AWS Cost Optimization Hub (đưa ra khuyến nghị tối ưu như chuyển sang Graviton instances, điều chỉnh kích thước, xóa tài nguyên không dùng), và AWS Compute Optimizer (đề xuất rightsizing cho EC2, EBS, Lambda, RDS dựa trên metrics thực tế). Mục tiêu là giúp doanh nghiệp không chỉ đạt được khoản tiết kiệm ban đầu mà còn duy trì tối ưu chi phí liên tục thông qua phân tích thường xuyên và triển khai các khuyến nghị điều chỉnh kích thước phù hợp.\nBlog 2 - Khám phá AWS Console: Chẩn đoán lỗi với Amazon Q Developer Bài blog giới thiệu tính năng \u0026ldquo;Diagnose with Amazon Q\u0026rdquo; của Amazon Q Developer - một trợ lý AI hỗ trợ chẩn đoán và khắc phục lỗi trực tiếp trong AWS Management Console. Khi gặp lỗi, người dùng chỉ cần nhấn nút \u0026ldquo;Diagnose with Amazon Q\u0026rdquo;, hệ thống sẽ sử dụng LLM (Large Language Models) để phân tích nguyên nhân gốc rễ dựa trên thông tin ngữ cảnh (error message, URL, IAM role). Sau đó, tính năng \u0026ldquo;Help me resolve\u0026rdquo; sẽ cung cấp hướng dẫn khắc phục chi tiết từng bước. Amazon Q hoạt động bằng cách: thu thập thông tin ngữ cảnh từ console, chủ động truy vấn thêm dữ liệu qua AWS Cloud Control API (trong phạm vi quyền IAM của người dùng), và tổng hợp thành giải pháp cụ thể. Mục tiêu là giảm MTTR (Mean Time To Repair), tiết kiệm thời gian troubleshooting, và giúp developers/operators xử lý sự cố hiệu quả hơn mà không cần chuyển qua lại nhiều console khác nhau.\nBlog 3 - Bắt đầu với Apache OFBiz và Amazon Aurora DSQL Bài blog trình bày case study thực tế về việc migrate ứng dụng Apache OFBiz (ERP/CRM mã nguồn mở với 837 bảng, 4161 indexes) từ PostgreSQL sang Amazon Aurora DSQL. Những thay đổi chính bao gồm: (1) Triển khai xác thực IAM-based thay vì password authentication, với token có thời hạn và quản lý connection pooling; (2) Điều chỉnh schema - thay đổi kiểu dữ liệu NUMERIC sang BIGINT, giảm VARCHAR size trong keys do giới hạn hiện tại của Aurora DSQL; (3) Xử lý transaction limits - chia batch data loading thành các lô 1000 rows mỗi lần commit; (4) Xử lý OCC (Optimistic Concurrency Control) - thêm retry logic cho transactions có thể bị abort do conflicts, vì Aurora DSQL chỉ hỗ trợ snapshot isolation và không lock resources trong quá trình build transaction. Kết quả chứng minh Aurora DSQL có thể hỗ trợ ứng dụng phức tạp với nỗ lực migration hợp lý, tập trung vào 4 khía cạnh: sử dụng đúng data types, IAM authentication, transaction size limits, và idempotent retry-able transactions.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " Trong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025\nThời gian: 08:30 ngày 06/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: AI-Driven Development Life Cycle: Reimagining Software Engineering\nThời gian: 14:00 ngày 03/10/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: AI/ML/GenAI on AWS\nThời gian: 8:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: DevOps on AWS\nThời gian: 8:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 5 Tên sự kiện: ​Theo AWS Well-Architected Security Pillar\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-aws-cognito/",
	"title": "Cấu hình AWS Cognito",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Trong bước này, chúng tôi trình bày cách sử dụng Amazon Cognito trong ứng dụng web English Journey để quản lý việc xác thực người dùng.\nNgười dùng (học viên) có thể đăng nhập bằng:\nEmail \u0026amp; mật khẩu Tài khoản Google (Gmail) Cognito đóng vai trò là dịch vụ quản lý danh tính trung tâm, cấp token để frontend và backend của English Journey sử dụng.\n5.4.1 Vai trò của Amazon Cognito trong kiến trúc Trong kiến trúc của English Journey:\nCognito User Pool lưu trữ thông tin định danh người dùng (email, tên, …). Xử lý các chức năng: Đăng ký (sign up) Đăng nhập (sign in) Quên mật khẩu / đổi mật khẩu Xác thực email Lưu trữ người dùng \u0026hellip; Tích hợp với AWS Amplify, giúp frontend React gọi các hàm signIn, signUp, v.v. dễ dàng. Kết nối với các nhà cung cấp đăng nhập xã hội (Social IdP): Google → cho người dùng đăng nhập bằng Gmail Sau khi đăng nhập thành công (bằng email, Google), Cognito trả về token, và các token này được dùng để bảo vệ API, Lambda và các tài nguyên phía backend.\n5.4.2 Tạo Cognito User Pool Các bước cấu hình chính:\nTạo User Pool\nĐăng nhập AWS Management Console → Amazon Cognito → User pools → Create user pool. Chọn Email là thông tin đăng nhập chính (sign-in identifier). Cho phép tự đăng ký (self-registration) để học viên tự tạo tài khoản. Cấu hình chính sách mật khẩu \u0026amp; xác thực\nThiết lập chính sách mật khẩu cơ bản (độ dài tối thiểu, ký tự đặc biệt, …). Bật xác thực email để yêu cầu người dùng xác nhận email trước khi sử dụng đầy đủ chức năng. Có thể tùy chỉnh nội dung email xác thực và email quên mật khẩu (nếu cần). Tạo app client\nTạo một public app client dành cho frontend web. Bật Cognito User Pool và social identity providers (Google) trong phần allowed identity providers. Cấu hình callback URLs và sign-out URLs (ví dụ: domain của frontend Amplify của English Journey). User Pool này sau đó sẽ được tham chiếu trong cấu hình Amplify và sử dụng ở frontend.\n5.4.3 Bật đăng nhập bằng Google (Gmail) Để hỗ trợ đăng nhập xã hội, chúng tôi thêm Google làm identity provider trong Cognito.\nĐăng nhập bằng Google (Gmail) Vào Google Cloud Console, tạo OAuth 2.0 Client ID cho ứng dụng web. Thiết lập Authorized redirect URI trỏ về URL callback của Cognito (được tạo từ User Pool). Lấy Client ID và Client Secret từ Google. Trong Cognito → User pool → Identity providers → Google: Dán Client ID và Client Secret. Map các thuộc tính như email, name của Google sang các thuộc tính chuẩn của Cognito. Sau khi cấu hình, người dùng có thể bấm \u0026ldquo;Sign in with Google\u0026rdquo; để đăng nhập bằng tài khoản Gmail của mình.\n5.4.4 Tích hợp Cognito với frontend Amplify Frontend React của English Journey sử dụng AWS Amplify Auth để kết nối với Cognito.\nVề mặt luồng xử lý:\nVới email/mật khẩu: Auth.signUp() dùng để đăng ký tài khoản mới. Auth.signIn() dùng để đăng nhập thông thường. Với Gmail (đăng nhập xã hội): Gọi Auth.federatedSignIn({ provider: 'Google' }). Amplify sẽ: Chuyển hướng người dùng sang trang đăng nhập Google. Người dùng xác thực thành công. Google trả về Cognito. Cognito trả về token và chuyển hướng lại frontend của English Journey. Trên giao diện trang đăng nhập, chúng tôi hiển thị hai lựa chọn chính:\nĐăng nhập bằng email \u0026amp; mật khẩu\rĐăng nhập bằng Google\rDù dùng cách nào thì cuối cùng người dùng vẫn nằm trong cùng một Cognito User Pool.\r5.4.5 Bảo mật và quản lý người dùng Với Cognito, chúng tôi có thể:\nBắt buộc xác thực email trước khi cho phép sử dụng đầy đủ chức năng.\nKiểm soát domain hợp lệ được phép gọi đăng nhập (qua phần callback URL).\nQuản lý người dùng tập trung:\nKhóa tài khoản\nReset mật khẩu\nXóa tài khoản\nMở rộng sau này với:\nMFA (Multi-Factor Authentication) Đăng nhập đa dạng nền tảng (Github, Facebook,\u0026hellip;) Trong phạm vi workshop này, chúng tôi tập trung vào:\nĐăng nhập bằng email \u0026amp; mật khẩu\nĐăng nhập ứng dụng qua Gmail\nXác thực email (OTP)\nTóm tắt Trong bước này, chúng tôi cấu hình Amazon Cognito làm dịch vụ quản lý danh tính cho English Journey:\nTạo User Pool để quản lý tài khoản và xác thực người dùng.\nCho phép người dùng đăng nhập bằng email, Google (Gmail).\nFrontend React + Amplify sử dụng token từ Cognito để truy cập an toàn đến các API và dịch vụ backend.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-create-ses/",
	"title": "Cấu hình Amazon SES để gửi email thông báo",
	"tags": [],
	"description": "",
	"content": "Mục tiêu SES sẽ được dùng để gửi các email xác thực cho học viên Mở rộng sau này với: Email chào mừng tạo tài khoản Email nhắc nhở học tập Lưu ý: SES là dịch vụ theo vùng (Region). Hãy đảm bảo bạn đang thao tác đúng Region đã dùng cho Amplify, Lambda và DynamoDB.\n5.5.1 – Mở Amazon SES Console Từ AWS Management Console, gõ “SES” trong ô tìm kiếm. Chọn Amazon Simple Email Service. Kiểm tra Region ở góc trên bên phải (ví dụ: ap-southeast-1). Nếu SES đang ở Region khác, hãy chuyển về Region của môi trường workshop. 5.5.2 – Xác thực địa chỉ email (Verified identity) Trong workshop này, chúng ta sẽ xác thực một địa chỉ email và dùng nó làm địa chỉ gửi (sender), ví dụ: email cá nhân của bạn.\nỞ menu bên trái của SES, chọn Verified identities. Nhấn Create identity. Chọn Email address. Trong ô Email address, nhập địa chỉ email bạn muốn dùng, ví dụ:\nyour-name+english-journey@gmail.com. Giữ các tùy chọn khác mặc định và nhấn Create identity. SES sẽ gửi một email xác thực tới địa chỉ này. Vào hộp thư, tìm email từ Amazon Web Services và bấm vào link xác thực. Quay lại SES console và bấm Refresh. Trạng thái của identity phải chuyển sang Verified. Từ thời điểm này, vì tài khoản vẫn đang ở SES Sandbox, SES chỉ cho phép gửi email từ và đến các địa chỉ đã được xác thực. Điều này là đủ cho môi trường học / workshop.\n5.5.3 – (Tùy chọn) Yêu cầu chuyển khỏi chế độ Sandbox Nếu sau này bạn muốn gửi email tới người học thật (địa chỉ chưa verified), bạn cần đưa tài khoản SES ra khỏi chế độ sandbox:\nTrong trang SES, chọn Account dashboard. Tại Your account details, kiểm tra Account status. Nếu vẫn là Sandbox, nhấn Request production access và làm theo hướng dẫn. Trong phạm vi workshop, bạn có thể ở chế độ sandbox miễn là chỉ gửi email giữa các địa chỉ đã xác thực.\n5.5.4 – Tạo Configuration Set (không bắt buộc, nhưng nên làm) Configuration set giúp nhóm toàn bộ email của ứng dụng English Journey lại với nhau và dễ dàng bật các tính năng theo dõi (CloudWatch metrics, event publishing, …) sau này.\nTrong menu SES, chọn Configuration sets. Nhấn Create configuration set. Đặt tên, ví dụ: english-journey-config. Giữ nguyên các tùy chọn mặc định và nhấn Create configuration set. Chúng ta sẽ sử dụng configuration set này khi gửi email từ các hàm Lambda.\n5.5.5 – Cấp quyền cho Lambda gửi email bằng SES Các Lambda như Daily Check-in hoặc Test Level result sẽ gửi email thông qua SES.\nVì vậy IAM role của Lambda phải được cấp quyền gọi API SES.\nQuyền này sẽ được cấu hình chi tiết ở Mục 5.7 – Tạo IAM Roles \u0026amp; Policies, nhưng bạn có thể tham khảo mẫu policy dưới đây:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ses:SendEmail\u0026#34;, \u0026#34;ses:SendRawEmail\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "English Journey Tổng quan English Journey là một ứng dụng web sáng tạo, được thiết kế để giúp người dùng học từ vựng tiếng Anh một cách có cấu trúc và tương tác. Nền tảng này sử dụng các dịch vụ của AWS để cung cấp trải nghiệm học tập mượt mà, giúp người dùng theo dõi tiến độ, tham gia vào các nội dung động và nhận phản hồi cá nhân hóa.\nCác Tính Năng Chính: Xác Thực Người Dùng: Sử dụng Amazon Cognito, người dùng có thể đăng ký, đăng nhập và truy cập tài liệu học tập của mình một cách an toàn.\nCác Mô-đun Học Tương Tác: Ứng dụng cung cấp nhiều bài học tương tác giúp người dùng mở rộng vốn từ vựng.\nTheo Dõi Tiến Độ: Người dùng có thể theo dõi tiến độ và sự hoàn thành các bài học từ vựng, với báo cáo chi tiết được tạo ra thông qua AWS Lambda và DynamoDB.\nThông báo: Hệ thống sử dụng Amazon SES để gửi email thông báo cho người dùng về bài học mới, các mốc tiến độ, cập nhật tài khoản và các thay đổi quan trọng khác.\nLưu Trữ Nội Dung: Tất cả tài liệu học tập được lưu trữ an toàn trên Amazon S3 với các quyền truy cập kiểm soát chặt chẽ.\nBảo Mật Web: Để bảo vệ nền tảng, AWS WAF giúp bảo vệ ứng dụng khỏi các mối đe dọa phổ biến trên web.\nGiám Sát và Cảnh Báo: AWS CloudWatch được sử dụng để giám sát hiệu suất của nền tảng, với các cảnh báo được cấu hình cho các vấn đề tiềm ẩn.\nCác Công Nghệ Được Sử Dụng: Frontend: Được xây dựng bằng các công nghệ web hiện đại, cho phép trải nghiệm người dùng mượt mà và phản hồi nhanh.\nBackend: Dựa trên các dịch vụ AWS như Lambda và DynamoDB, đảm bảo tính mở rộng và hiệu suất.\nLưu Trữ: Tất cả dữ liệu và nội dung media được lưu trữ an toàn trên Amazon S3.\nNội dung Tổng quan về workshop Các bước chuẩn bị Create Amplify AWS Cognito Amazon SES để gửi email thông báo CloudWatch IAM Roles - Policies Amazon Route 53 Clean up "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-create-cloudwatch/",
	"title": "Cấu hình Amazon CloudWatch",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Để hiểu hệ thống hoạt động như thế nào và phản ứng nhanh khi có lỗi, nhóm sử dụng Amazon CloudWatch cho:\nThu thập log từ các Lambda function, Theo dõi metric (số lần gọi, lỗi, throttling, thời gian xử lý), 5.6.1 CloudWatch Logs cho Lambda và API Mặc định, mọi Lambda được tạo bởi Amplify đều ghi log vào CloudWatch Logs.\nTrong dự án này, log được dùng để:\nTheo dõi request cho: Bài kiểm tra trình độ, Nộp bài quiz, Tra từ điển / từ vựng, Debug lỗi đầu vào, lỗi phân quyền (IAM) hoặc timeout, Ghi lại các sự kiện quan trọng. Ngoài log mặc định, một số function còn ghi log dạng JSON có cấu trúc, giúp dễ tìm kiếm theo userId, requestId hoặc feature.\n5.6.2 Metric cho các dịch vụ chính CloudWatch tự động cung cấp metric cho:\nLambda – số lần gọi, số lỗi, thời gian thực thi, số concurrent execution, DynamoDB – dung lượng đọc/ghi, số request bị throttled, S3 / CloudFront – băng thông, số request, WAF – số request được cho phép / bị chặn. Trong workshop, nhóm tập trung vào một số metric quan trọng:\nError count / Error rate của các Lambda chính, Duration của function xử lý Level Test và Quiz để phát hiện vấn đề hiệu năng, ThrottledRequests của DynamoDB để xem cấu hình capacity có đủ hay không. 5.6.3 CloudWatch Dashboard (tuỳ chọn) Để quan sát nhanh tình trạng hệ thống, nhóm tạo một CloudWatch Dashboard nhỏ hiển thị:\nBiểu đồ tỷ lệ lỗi Lambda theo thời gian, Thời gian thực thi của các function LevelTest và Dictionary, (Tuỳ chọn) số request bị chặn bởi AWS WAF. Dashboard không bắt buộc cho workshop, nhưng giúp minh hoạ rõ hơn khi có nhiều sinh viên truy cập hệ thống.\nTóm tắt CloudWatch giúp hoàn thiện khả năng giám sát cho English Journey bằng cách cung cấp:\nLog để phân tích và debug, Metric \u0026amp; dashboard để quan sát xu hướng, Kết hợp với Amplify, SES và WAF, đây là một cấu hình vận hành đủ chắc cho dự án workshop này.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại Amazon từ 08/09/2025 đến 08/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia thực tập và học về cloud, qua đó cải thiện kỹ năng lập trình, ứng dụng cloud, phân tích, viết báo cáo, giao tiếp….\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỉ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào. Cải thiện trong cách tư duy giải quyết vấn đề. Tính nhanh nhẹn và tiếp thu nhanh hơn. Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Mình hài lòng nhất với môi trường làm việc hỗ trợ và sự hướng dẫn rõ ràng từ mentor, giúp mình học hỏi và phát triển trong khi làm các công việc phù hợp với chuyên ngành. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Cần tổ chức thêm các sự kiện giao lưu, kết nối ngoài giờ làm việc, và có các buổi phản hồi để theo dõi tiến trình và cải thiện. Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Có, mình sẽ khuyên họ thực tập ở đây. Môi trường làm việc hỗ trợ, cơ hội học hỏi và giờ làm việc linh hoạt là những điểm cộng lớn. Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Nên có thêm các sự kiện xây dựng đội nhóm và các buổi phản hồi định kỳ để cải thiện trải nghiệm thực tập. Bạn có muốn tiếp tục chương trình này trong tương lai? Có, mình rất muốn tiếp tục. Kinh nghiệm trong kỳ thực tập rất quý giá và mình muốn có thêm cơ hội học hỏi. Góp ý khác (tự do chia sẻ): Kỳ thực tập rất tuyệt vời. Nếu có thể mở rộng phạm vi công việc cho thực tập sinh, trải nghiệm sẽ hoàn thiện hơn. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.7-create-iam-roles-policies/",
	"title": "IAM Roles &amp; Policies",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Phần này giải thích cách IAM roles và policies được thiết kế cho ứng dụng English Journey.\nPhần lớn các role được sinh tự động bởi AWS Amplify, nhưng chúng ta vẫn cần hiểu:\nCó những role nào tồn tại, Mỗi role được phép làm gì (DynamoDB, SES,…), Và cách chúng ta áp dụng nguyên tắc ít quyền nhất (least privilege). 5.7.1 Tổng quan IAM trong kiến trúc Trong kiến trúc từ các mục 5.3–5.6, IAM là “chất keo” kết nối các dịch vụ với nhau:\nAmplify sử dụng IAM roles để triển khai các CloudFormation stack và host frontend. Các hàm Lambda dùng execution role để truy cập DynamoDB, S3 và SES (để gửi email). CloudWatch và SES dựa vào IAM để có thể gửi cảnh báo và email thông báo một cách chính xác. Mục tiêu thiết kế là mỗi thành phần chỉ nhận đúng số quyền tối thiểu mà nó cần.\n5.7.2 Lambda execution roles Khi chúng ta định nghĩa các backend function trong Amplify (Level Test, My Learning, Dictionary, Vocabulary, …), Amplify sẽ tự động tạo một Lambda execution role cho mỗi function.\nMỗi role sẽ có:\nTrust policy – cho phép dịch vụ Lambda được assume (nhận) role này:\n{ \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;lambda.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.8-route-53/",
	"title": "Cấu hình Amazon Route 53",
	"tags": [],
	"description": "",
	"content": "5.8 Cấu hình Amazon Route 53 (Tên miền riêng) Bước này sẽ kết nối frontend English Journey chạy trên AWS Amplify với một tên miền riêng được quản lý bởi Amazon Route 53.\n🔗 Tên miền dùng trong workshop\nTrong môi trường demo, ứng dụng sử dụng tên miền\nenglishjourney.xyz – trang web cuối cùng truy cập tại:\nhttps://www.englishjourney.xyz/\n5.8.1 Tạo / kiểm tra hosted zone Mở console Route 53 → Hosted zones → Create hosted zone. Nhập tên miền của bạn, ví dụ englishjourney.xyz, chọn loại Public hosted zone. Route 53 sẽ tạo sẵn các bản ghi NS và SOA cho zone. Nếu domain đăng ký ở nơi khác, copy các bản ghi NS này sang nhà đăng ký domain để trỏ DNS về Route 53. 5.8.2 Kết nối tên miền trong AWS Amplify Vào console AWS Amplify → chọn ứng dụng English Journey.\nMenu bên trái chọn Domain management → Add domain.\nChọn hosted zone englishjourney.xyz.\nMap các đường dẫn:\nenglishjourney.xyz → nhánh chính (production) www.englishjourney.xyz → redirect về domain gốc Amplify sẽ tự động tạo các bản ghi A / AAAA và CNAME tương ứng trong Route 53.\n5.8.3 Kiểm tra hoạt động Chờ vài phút để DNS và chứng chỉ SSL được cấp.\nMở trình duyệt và truy cập:\nhttps://www.englishjourney.xyz/ Xác nhận trang chủ English Journey hiển thị đúng và chạy bằng HTTPS.\nGhi lại URL này trong phần báo cáo / slide như điểm truy cập chính của ứng dụng trong workshop.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.9-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Phần này hướng dẫn bạn xoá các tài nguyên AWS đã được tạo hoặc sử dụng trong workshop English Journey, để tránh phát sinh chi phí không cần thiết.\nChỉ nên thực hiện bước này khi bạn đã hoàn tất việc thử nghiệm kiến trúc.\n5.9.1 – Xoá ứng dụng Amplify và frontend hosting Mở console Amplify ở đúng Region đã dùng cho workshop. Chọn Amplify app đang host frontend của English Journey. Chọn Actions → Delete app (hoặc nút Delete trong trang chi tiết app). Xác nhận xoá theo hướng dẫn. Khi xoá Amplify app:\nAmplify sẽ tự động xoá phần frontend hosting, và thường xoá luôn các backend stack mà Amplify đã tạo (Cognito, Lambda, DynamoDB),\ntrừ khi bạn chọn giữ lại chúng trong quá trình xoá. Hãy đọc kỹ nội dung trong hộp thoại xác nhận để tránh xoá nhầm tài nguyên quan trọng.\n5.9.2 – Xoá các backend resource còn sót lại Tuỳ cách bạn tạo backend, sau khi xoá Amplify app vẫn có thể còn một số tài nguyên tồn tại.\nTrong AWS console, tại đúng Region workshop, hãy kiểm tra các dịch vụ sau:\nCognito\nXoá các User Pool hoặc Identity Pool được tạo riêng cho workshop. Lambda\nXoá các Lambda function chỉ phục vụ English Journey (ví dụ: function kiểm tra trình độ, daily reminder, xử lý từ vựng). DynamoDB\nXoá các bảng DynamoDB chỉ dùng cho dữ liệu workshop (tiến độ học, câu hỏi, từ vựng, …) nếu bạn không còn cần. 5.9.3 – Dọn dẹp SES, CloudWatch và WAF Ngoài backend chính, workshop còn sử dụng Amazon SES, CloudWatch và (tuỳ chọn) AWS WAF.\nAmazon SES Mở console Amazon SES. Trong mục Verified identities: Xoá các địa chỉ email (identity) được tạo chỉ để phục vụ workshop (ví dụ: email gửi thử hoặc nhận thử). Trong mục Configuration sets: Xoá configuration set dùng cho ứng dụng English Journey (ví dụ: english-journey-config), nếu bạn không có ý định tái sử dụng. Nếu bạn đã yêu cầu thoát khỏi chế độ sandbox của SES chỉ để phục vụ workshop, hãy xem lại cách sử dụng và hạn mức gửi email; tuy nhiên không có tài nguyên riêng nào cần xoá cho việc đó.\nCloudWatch Mở console CloudWatch. Ở mục Log groups, xoá: các log group của Lambda function thuộc English Journey, AWS WAF Nếu bạn đã cấu hình một WAF Web ACL riêng cho frontend của English Journey:\nMở console AWS WAF. Tìm Web ACL gắn với CloudFront distribution hoặc Amplify app của workshop. Nếu Web ACL này chỉ phục vụ riêng workshop, bạn có thể xoá nó. 5.9.4 – Dọn dẹp IAM roles và policies Cuối cùng, hãy rà soát IAM để đảm bảo không còn role/policy nào bị “mồ côi”:\nTrong console IAM, vào mục Roles:\nTìm các role được tạo chỉ cho workshop (ví dụ: các Lambda execution role tuỳ chỉnh, hoặc role có tên chứa English Journey / workshop). Trước khi xoá, hãy kiểm tra chắc chắn không còn Lambda, dịch vụ hay người dùng nào đang dùng role đó. Trong mục Policies:\nXoá các customer-managed policy chỉ phục vụ workshop, đặc biệt là: policy cấp quyền ses:SendEmail / ses:SendRawEmail cho Lambda, các policy chỉ gắn với những role tạm thời. Không xoá các IAM role / policy dùng chung hoặc đang phục vụ hệ thống production.\nSau khi hoàn thành các bước trên, môi trường AWS của bạn sẽ không còn các tài nguyên được tạo riêng cho workshop English Journey.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]